{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fed33d-be68-4c1b-a045-30f853f1e6a5",
   "metadata": {},
   "source": [
    "# Spark Predicate Pushdown\n",
    "\n",
    "This notebook demonstrates how to verify prediate pushdown from Spark to Vast DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3485e1-107b-481a-9fb5-a0825e6a06b0",
   "metadata": {},
   "source": [
    "## Load Endpoint Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655dbdd-e541-429e-b653-ace158721613",
   "metadata": {},
   "source": [
    "These environment variables have been set when your docker container was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204f19da-1de4-4e54-95e5-be3409dfaea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "DOCKER_HOST_OR_IP=10.143.11.241\n",
      "---\n",
      "VASTDB_ENDPOINT=http://172.200.204.2:80\n",
      "VASTDB_ACCESS_KEY=QXN5\n",
      "VASTDB_SECRET_KEY=****oLGr\n",
      "VASTDB_TWITTER_INGEST_BUCKET=csnow-db\n",
      "VASTDB_TWITTER_INGEST_SCHEMA=social_media\n",
      "VASTDB_TWITTER_INGEST_TABLE=tweets\n",
      "---\n",
      "S3_ENDPOINT=http://172.200.204.2:80\n",
      "S3_ACCESS_KEY=QXN5\n",
      "S3_SECRET_KEY=****oLGr\n",
      "S3A_ICEBERG_URI=s3a://csnow-bucket/iceberg/\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DOCKER_HOST_OR_IP = os.getenv(\"DOCKER_HOST_OR_IP\")\n",
    "\n",
    "VASTDB_ENDPOINT = os.getenv(\"VASTDB_ENDPOINT\")\n",
    "VASTDB_ACCESS_KEY = os.getenv(\"VASTDB_ACCESS_KEY\")\n",
    "VASTDB_SECRET_KEY = os.getenv(\"VASTDB_SECRET_KEY\")\n",
    "\n",
    "VASTDB_TWITTER_INGEST_BUCKET = os.getenv(\"VASTDB_TWITTER_INGEST_BUCKET\")\n",
    "VASTDB_TWITTER_INGEST_SCHEMA = os.getenv(\"VASTDB_TWITTER_INGEST_SCHEMA\")\n",
    "VASTDB_TWITTER_INGEST_TABLE = os.getenv(\"VASTDB_TWITTER_INGEST_TABLE\")\n",
    "\n",
    "S3_ENDPOINT = os.getenv(\"S3A_ENDPOINT\")\n",
    "S3_ACCESS_KEY = os.getenv(\"S3A_ACCESS_KEY\")\n",
    "S3_SECRET_KEY = os.getenv(\"S3A_SECRET_KEY\")\n",
    "\n",
    "S3A_ICEBERG_URI = os.getenv(\"S3A_ICEBERG_URI\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---\n",
    "DOCKER_HOST_OR_IP={DOCKER_HOST_OR_IP}\n",
    "---\n",
    "VASTDB_ENDPOINT={VASTDB_ENDPOINT}\n",
    "VASTDB_ACCESS_KEY={VASTDB_ACCESS_KEY[-4:]}\n",
    "VASTDB_SECRET_KEY=****{VASTDB_SECRET_KEY[-4:]}\n",
    "VASTDB_TWITTER_INGEST_BUCKET={VASTDB_TWITTER_INGEST_BUCKET}\n",
    "VASTDB_TWITTER_INGEST_SCHEMA={VASTDB_TWITTER_INGEST_SCHEMA}\n",
    "VASTDB_TWITTER_INGEST_TABLE={VASTDB_TWITTER_INGEST_TABLE}\n",
    "---\n",
    "S3_ENDPOINT={S3_ENDPOINT}\n",
    "S3_ACCESS_KEY={S3_ACCESS_KEY[-4:]}\n",
    "S3_SECRET_KEY=****{VASTDB_SECRET_KEY[-4:]}\n",
    "S3A_ICEBERG_URI={S3A_ICEBERG_URI}\n",
    "---\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf87ca-92d2-46a1-abda-aa59b9a3f4ab",
   "metadata": {},
   "source": [
    "## Specify other Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6596d81a-04e2-4007-9777-bf406c6ea190",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_APPLICATION_NAME='Spark Demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e356c0a-a13c-48e8-bf5f-0603a6953e31",
   "metadata": {},
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7385eee4-6b08-4be0-b6de-d95b64dac1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 150)\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAll([\n",
    "    (\"spark.driver.host\", socket.gethostbyname(socket.gethostname())),\n",
    "    (\"spark.sql.execution.arrow.pyspark.enabled\", \"false\"),\n",
    "     # VASTDB\n",
    "    (\"spark.sql.catalog.ndb\", 'spark.sql.catalog.ndb.VastCatalog'),\n",
    "    (\"spark.ndb.endpoint\", VASTDB_ENDPOINT),\n",
    "    (\"spark.ndb.data_endpoints\", VASTDB_ENDPOINT),\n",
    "    (\"spark.ndb.access_key_id\", VASTDB_ACCESS_KEY),\n",
    "    (\"spark.ndb.secret_access_key\", VASTDB_SECRET_KEY),\n",
    "    (\"spark.driver.extraClassPath\", '/usr/local/spark/jars/spark3-vast-3.4.1-f93839bfa38a/*'),\n",
    "    (\"spark.executor.extraClassPath\", '/usr/local/spark/jars/spark3-vast-3.4.1-f93839bfa38a/*'),\n",
    "    (\"spark.sql.extensions\", 'ndb.NDBSparkSessionExtension'),\n",
    "    # ICEBERG\n",
    "    (\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\"),\n",
    "    (\"spark.sql.catalog.iceberg.type\", \"hive\"),\n",
    "    (\"spark.sql.catalog.iceberg.uri\", f\"thrift://{DOCKER_HOST_OR_IP}:9083\"),\n",
    "    # S3A\n",
    "    (\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\"),\n",
    "    (\"fs.s3a.endpoint\", S3_ENDPOINT),\n",
    "    (\"fs.s3a.access.key\", S3_ACCESS_KEY),\n",
    "    (\"fs.s3a.secret.key\", S3_SECRET_KEY),\n",
    "    (\"fs.s3a.endpoint.region\", \"vast\"),\n",
    "    (\"fs.s3a.connection.ssl.enabled\", \"false\"),\n",
    "    # Hive\n",
    "    (\"hive.metastore.uris\", f\"thrift://{DOCKER_HOST_OR_IP}:9083\"),\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(SPARK_APPLICATION_NAME) \\\n",
    "    .config(conf=conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"DEBUG\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set logging for a specific class/package\n",
    "logging.getLogger(\"com.example.HelloWorldCatalog\").setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"Spark successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d558bb-2071-440a-b7b4-f86eda0c8e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"None\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcc9da7d650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952bc9b-f97d-4f87-87d8-9e3901163e0c",
   "metadata": {},
   "source": [
    "## Social Media Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e7c46a-1baa-40c7-bf6a-52d2a2079dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+---------------------------------------------------------+\n",
      "|created_at   |id                  |id_str              |text                                                     |\n",
      "+-------------+--------------------+--------------------+---------------------------------------------------------+\n",
      "|1732208274768|-7643870142078251013|-7643870142078251013|so excited about how clever MobileDevelopment is!        |\n",
      "|1732208274768|1020245429851211082 |1020245429851211082 |can't believe how interesting AI is!                     |\n",
      "|1732208274768|2617468679894608857 |2617468679894608857 |prepared for how beautiful CloudEngineer is!             |\n",
      "|1732208274869|-3100632458456822   |-3100632458456822   |eager to see how amazing WebDevelopment is!              |\n",
      "|1732208274869|-6907312571603061960|-6907312571603061960|looking forward to see how lovely SoftwareDevelopment is!|\n",
      "|1732208274869|-3012906547616722072|-3012906547616722072|finally got how beautiful Agile is!                      |\n",
      "|1732208274869|-4196485847106647115|-4196485847106647115|eager to see how beautiful Agile is!                     |\n",
      "|1732208274869|-4032196169367521327|-4032196169367521327|can't wait to see how fantastic Security is!             |\n",
      "|1732208274869|-6418918754352525203|-6418918754352525203|inspired by how lovely Security is!                      |\n",
      "|1732208274869|1603970341201682038 |1603970341201682038 |impressed with how nice DevOpsEngineering is!            |\n",
      "|1732208274869|5381813079630643176 |5381813079630643176 |inspired by how kind IoT is!                             |\n",
      "|1732208274869|-6993575410907140870|-6993575410907140870|just discovered how fantastic OpenSource is!             |\n",
      "|1732208274869|-8297742997571818506|-8297742997571818506|blown away by how brilliant SecurityEngineering is!      |\n",
      "|1732208274869|-680635112296625023 |-680635112296625023 |just discovered how perfect AI is!                       |\n",
      "|1732208274971|-4712879233424671375|-4712879233424671375|can't wait to see how beautiful Blockchain is!           |\n",
      "|1732208274971|1126266839692793283 |1126266839692793283 |eager to see how clever CloudEngineer is!                |\n",
      "|1732208274971|7004216700398130448 |7004216700398130448 |blown away by how interesting Agile is!                  |\n",
      "|1732208274971|6523371880127967106 |6523371880127967106 |looking forward to see how funny OpenSource is!          |\n",
      "|1732208274971|-1253123398442262397|-1253123398442262397|just discovered how nice OpenSource is!                  |\n",
      "|1732208274971|882386532907502832  |882386532907502832  |amazed by how funny WebDevelopment is!                   |\n",
      "+-------------+--------------------+--------------------+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM ndb.`csnow-db`.social_media.tweets\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb48db-758a-44b9-844e-a664e4877e4f",
   "metadata": {},
   "source": [
    "## Pushdown created_at (Int 64) greater than predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff3b715-c77b-4979-8bbb-40d9a00fbf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter ('created_at > 123456)\n",
      "   +- 'UnresolvedRelation [ndb, csnow-db, social_media, tweets], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "created_at: bigint, id: bigint, id_str: string, text: string\n",
      "Project [created_at#29L, id#30L, id_str#31, text#32]\n",
      "+- Filter (created_at#29L > cast(123456 as bigint))\n",
      "   +- SubqueryAlias ndb.`csnow-db`.social_media.tweets\n",
      "      +- RelationV2[created_at#29L, id#30L, id_str#31, text#32] ndb.`csnow-db`.social_media.tweets csnow-db/social_media/tweets\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(created_at#29L) AND (created_at#29L > 123456))\n",
      "+- RelationV2[created_at#29L, id#30L, id_str#31, text#32] csnow-db/social_media/tweets\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- BatchScan csnow-db/social_media/tweets[created_at#29L, id#30L, id_str#31, text#32] VastScan{schemed_name=(csnow-db/social_media/tweets, -1935090858), pushed_down_limit=null, pushed_down_predicates=[[created_at IS NOT NULL], [created_at > 123456]]} RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT * FROM ndb.`csnow-db`.social_media.tweets\n",
    "WHERE created_at > 123456\n",
    "\"\"\")\n",
    "\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b23db-debd-45ef-b21d-ddcd35ebbecd",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "Note the following in the Physical Plan: `pushed_down_predicates=[[created_at IS NOT NULL], [created_at > 123456]]`\n",
    "\n",
    "This demonstrates that the predicate `created_at > 123456` **WAS** pushed down to Vast DB and taking advantage of filtering the dataset **BEFORE** returning it to Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70066a2-211a-4031-852e-35d70e3c7285",
   "metadata": {},
   "source": [
    "## Pushdown text (String) equality predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c6b6c3-5d4b-4839-8580-84cb1570618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter ('text = a)\n",
      "   +- 'UnresolvedRelation [ndb, csnow-db, social_media, tweets], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "created_at: bigint, id: bigint, id_str: string, text: string\n",
      "Project [created_at#41L, id#42L, id_str#43, text#44]\n",
      "+- Filter (text#44 = a)\n",
      "   +- SubqueryAlias ndb.`csnow-db`.social_media.tweets\n",
      "      +- RelationV2[created_at#41L, id#42L, id_str#43, text#44] ndb.`csnow-db`.social_media.tweets csnow-db/social_media/tweets\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(text#44) AND (text#44 = a))\n",
      "+- RelationV2[created_at#41L, id#42L, id_str#43, text#44] csnow-db/social_media/tweets\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- BatchScan csnow-db/social_media/tweets[created_at#41L, id#42L, id_str#43, text#44] VastScan{schemed_name=(csnow-db/social_media/tweets, -1731650491), pushed_down_limit=null, pushed_down_predicates=[[text IS NOT NULL], [text = 'a']]} RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT * FROM ndb.`csnow-db`.social_media.tweets\n",
    "WHERE text = 'a'\n",
    "\"\"\")\n",
    "\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe5286-1a78-46db-b9f3-f11463a96b52",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "Note the following in the Physical Plan: `pushed_down_predicates=[[text IS NOT NULL], [text = 'a']]`\n",
    "\n",
    "This demonstrates that the predicate `text = 'a'` **WAS** pushed down to Vast DB and taking advantage of filtering the dataset **BEFORE** returning it to Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced6680-4f86-4c86-9383-0211fb5172cd",
   "metadata": {},
   "source": [
    "## Pushdown text (String) LIKE predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2aa584-465d-4c0b-87be-e581749eaae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter 'text LIKE a%\n",
      "   +- 'UnresolvedRelation [ndb, csnow-db, social_media, tweets], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "created_at: bigint, id: bigint, id_str: string, text: string\n",
      "Project [created_at#53L, id#54L, id_str#55, text#56]\n",
      "+- Filter text#56 LIKE a%\n",
      "   +- SubqueryAlias ndb.`csnow-db`.social_media.tweets\n",
      "      +- RelationV2[created_at#53L, id#54L, id_str#55, text#56] ndb.`csnow-db`.social_media.tweets csnow-db/social_media/tweets\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(text#56) AND StartsWith(text#56, a))\n",
      "+- RelationV2[created_at#53L, id#54L, id_str#55, text#56] csnow-db/social_media/tweets\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter StartsWith(text#56, a)\n",
      "+- *(1) ColumnarToRow\n",
      "   +- BatchScan csnow-db/social_media/tweets[created_at#53L, id#54L, id_str#55, text#56] VastScan{schemed_name=(csnow-db/social_media/tweets, -198082486), pushed_down_limit=null, pushed_down_predicates=[[text IS NOT NULL]]} RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT * FROM ndb.`csnow-db`.social_media.tweets\n",
    "WHERE text like 'a%'\n",
    "\"\"\")\n",
    "\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3adaf49-e160-44c8-bdae-5e32ad70d310",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "Note the following in the Physical Plan: `pushed_down_predicates=[[text IS NOT NULL]]`\n",
    "\n",
    "This demonstrates that the predicate `text like 'a'` was **NOT** pushed down to Vast DB and therefore does not take advantage of filtering the dataset before returning it to Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0cbc3-7714-48ee-b7d3-eb62e5403bb0",
   "metadata": {},
   "source": [
    "## Pushdown text (String) substring (LIKE %a%) predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1e88d6-5f1b-4d4a-b305-9dd9fdddaede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter ('substring('text, 1, 1) = a)\n",
      "   +- 'UnresolvedRelation [ndb, csnow-db, social_media, tweets], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "created_at: bigint, id: bigint, id_str: string, text: string\n",
      "Project [created_at#65L, id#66L, id_str#67, text#68]\n",
      "+- Filter (substring(text#68, 1, 1) = a)\n",
      "   +- SubqueryAlias ndb.`csnow-db`.social_media.tweets\n",
      "      +- RelationV2[created_at#65L, id#66L, id_str#67, text#68] ndb.`csnow-db`.social_media.tweets csnow-db/social_media/tweets\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(text#68) AND (substring(text#68, 1, 1) = a))\n",
      "+- RelationV2[created_at#65L, id#66L, id_str#67, text#68] csnow-db/social_media/tweets\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter (substring(text#68, 1, 1) = a)\n",
      "+- *(1) ColumnarToRow\n",
      "   +- BatchScan csnow-db/social_media/tweets[created_at#65L, id#66L, id_str#67, text#68] VastScan{schemed_name=(csnow-db/social_media/tweets, 101095318), pushed_down_limit=null, pushed_down_predicates=[[text IS NOT NULL]]} RuntimeFilters: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT * FROM ndb.`csnow-db`.social_media.tweets\n",
    "WHERE substring(text, 1, 1) = 'a'\n",
    "\"\"\")\n",
    "\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d9727-a14b-4605-a964-faf10da95769",
   "metadata": {},
   "source": [
    "**IMPORTANT:**\n",
    "\n",
    "Note the following in the Physical Plan: `pushed_down_predicates=[[text IS NOT NULL]]`\n",
    "\n",
    "This demonstrates that the predicate `substring(text, 1, 1) = 'a'` was **NOT** pushed down to Vast DB and therefore does not take advantage of filtering the dataset before returning it to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637658e2-0319-41a1-816f-58e75e86ba73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
