{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "debbc9fd-efad-4f93-9cd1-366eb20780e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53168a20-339e-40a8-8221-fc7e767e3fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKER_HOST_OR_IP='10.143.11.241'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load environment variables for Kafka and VastDB connectivity\n",
    "DOCKER_HOST_OR_IP = os.getenv(\"DOCKER_HOST_OR_IP\", \"localhost\")\n",
    "VASTDB_ENDPOINT = os.getenv(\"VASTDB_ENDPOINT\")\n",
    "VASTDB_ACCESS_KEY = os.getenv(\"VASTDB_ACCESS_KEY\")\n",
    "VASTDB_SECRET_KEY = os.getenv(\"VASTDB_SECRET_KEY\")\n",
    "\n",
    "VASTDB_FRAUD_DETECTION_BUCKET = os.getenv(\"VASTDB_FRAUD_DETECTION_BUCKET\")\n",
    "VASTDB_FRAUD_DETECTION_SCHEMA = os.getenv(\"VASTDB_FRAUD_DETECTION_SCHEMA\")\n",
    "VASTDB_FRAUD_DETECTION_TABLE = 'fraud'\n",
    "\n",
    "# Kafka broker configuration using environment variable\n",
    "DOCKER_HOST_OR_IP = os.getenv(\"DOCKER_HOST_OR_IP\")\n",
    "print(f\"{DOCKER_HOST_OR_IP=}\")\n",
    "\n",
    "kafka_brokers = f\"{DOCKER_HOST_OR_IP}:19092\"\n",
    "kafka_topic = \"stock-settlement\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96b90c-5a11-4cc2-b7f4-9438632deec9",
   "metadata": {},
   "source": [
    "# Fraud Producer (Spark Streaming app that will simulate stock settlement data) -> Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e607bf4-c1e7-455c-9d9c-f046ad2f0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced: 88839 records\n",
      "Graceful shutdown initiated...\n",
      "Produced: 95353 records\n",
      "Shutting down Spark session...\n",
      "Spark session stopped. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "from faker import Faker\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Spark configuration\n",
    "conf = SparkConf()\n",
    "conf.setAll([\n",
    "    (\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.4.3,\"\n",
    "                             \"org.apache.logging.log4j:log4j-slf4j2-impl:2.19.0,\"\n",
    "                             \"org.apache.logging.log4j:log4j-api:2.19.0,\"\n",
    "                             \"org.apache.logging.log4j:log4j-core:2.19.0\"),\n",
    "    (\"spark.jars.excludes\", \"org.slf4j:slf4j-api,org.slf4j:slf4j-log4j12\"),\n",
    "    (\"spark.driver.userClassPathFirst\", \"true\"),\n",
    "    (\"spark.executor.userClassPathFirst\", \"true\"),\n",
    "    (\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"FakeStockSettlementKafkaStreaming\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Graceful shutdown flag\n",
    "should_shutdown = False\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    global should_shutdown\n",
    "    print(\"\\nGraceful shutdown initiated...\")\n",
    "    should_shutdown = True\n",
    "\n",
    "# Register signal handlers\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "signal.signal(signal.SIGTERM, signal_handler)\n",
    "\n",
    "# Function to generate a fake stock settlement\n",
    "def create_stock_settlement(fraud_percentage=0.03, status_weights=None):\n",
    "    \"\"\"Generate a fake stock settlement record with custom fraud percentage and status distribution.\"\"\"\n",
    "    if status_weights is None:\n",
    "        status_weights = {\"Settled\": 0.8, \"Pending\": 0.2, \"Failed\": 0.1}\n",
    "\n",
    "    is_fraud = random.random() < fraud_percentage  # Fraud percentage\n",
    "    if is_fraud:\n",
    "        return {\n",
    "            \"transaction_id\": fake.uuid4(),\n",
    "            \"settlement_date\": fake.date_this_year().isoformat(),\n",
    "            \"stock_symbol\": fake.lexify(text='???', letters='ABCDEFGHIJKLMNOPQRSTUVWXYZ'),\n",
    "            \"quantity\": random.randint(1, 100000),\n",
    "            \"price\": round(random.uniform(5000, 25000), 2),  # Variable fraud price\n",
    "            \"buyer\": \"Fraudulent Company\" if random.random() < 0.5 else fake.company(),\n",
    "            \"seller\": \"Fraudulent Company\" if random.random() < 0.5 else fake.company(),\n",
    "            \"trade_date\": fake.date_this_year().isoformat(),\n",
    "            \"status\": \"Fraudulent\"\n",
    "        }\n",
    "    else:\n",
    "        buyer = fake.company()\n",
    "        seller = buyer if random.random() < 0.05 else fake.company()  # 5% chance buyer and seller are the same\n",
    "        return {\n",
    "            \"transaction_id\": fake.uuid4(),\n",
    "            \"settlement_date\": fake.date_this_year().isoformat(),\n",
    "            \"stock_symbol\": fake.lexify(text='???', letters='ABCDEFGHIJKLMNOPQRSTUVWXYZ'),\n",
    "            \"quantity\": random.randint(1, 10000),\n",
    "            \"price\": round(random.uniform(10, 50000), 2),\n",
    "            \"buyer\": buyer,\n",
    "            \"seller\": seller,\n",
    "            \"trade_date\": fake.date_this_year().isoformat(),\n",
    "            \"status\": random.choices(\n",
    "                list(status_weights.keys()), \n",
    "                weights=list(status_weights.values()), \n",
    "                k=1\n",
    "            )[0]\n",
    "        }\n",
    "\n",
    "# Continuously generate and push stock settlements to Kafka\n",
    "record_count = 0\n",
    "\n",
    "try:\n",
    "    while not should_shutdown:\n",
    "        # Randomize batch size for dynamic event generation\n",
    "        batch_size = random.randint(1000, 8000)  # Different amount of events per trade date\n",
    "        \n",
    "        # Generate stock settlements\n",
    "        records = [\n",
    "            {\"key\": settlement[\"transaction_id\"], \"value\": json.dumps(settlement)}\n",
    "            for settlement in [create_stock_settlement() for _ in range(batch_size)]\n",
    "        ]\n",
    "\n",
    "        # Create DataFrame from stock settlements\n",
    "        df = spark.createDataFrame(records)\n",
    "\n",
    "        # Write DataFrame as JSON to Kafka topic\n",
    "        df.write \\\n",
    "          .format(\"kafka\") \\\n",
    "          .option(\"kafka.bootstrap.servers\", kafka_brokers) \\\n",
    "          .option(\"topic\", kafka_topic) \\\n",
    "          .option(\"kafka.producer.batch.size\", 1000000) \\\n",
    "          .save()\n",
    "\n",
    "        record_count += batch_size\n",
    "        print(f\"Produced: {record_count} records\", end=\"\\r\")\n",
    "\n",
    "        # Reduce sleep time or remove it for high throughput\n",
    "        time.sleep(0.1)  # Adjust sleep time as needed, or remove it entirely for max throughput\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    print(\"\\nShutting down Spark session...\")\n",
    "    spark.stop()\n",
    "    print(\"Spark session stopped. Goodbye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229d567-c318-4b31-96d4-02f63fc14eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
