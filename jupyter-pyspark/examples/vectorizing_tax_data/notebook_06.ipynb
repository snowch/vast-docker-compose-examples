{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2594876-3ca3-4f42-8bf9-7beaff80300f",
   "metadata": {},
   "source": [
    "# Querying for Cross-Source Similarity\n",
    "\n",
    "**Purpose**:\n",
    "  1. Connect to the vector database and collection initialized in Notebook 05.\n",
    "  2. Identify a specific taxpayer profile in the synthetic data known to exhibit\n",
    "     suspicious cross-source patterns (e.g., low declared income combined with\n",
    "     high-value property ownership, based on Notebook 00 generation logic).\n",
    "  3. Retrieve the vector embedding for this chosen 'query' profile from the DB.\n",
    "  4. Perform a similarity search (query) against the vector database using the\n",
    "     query vector to find the N most similar taxpayer profiles based on their\n",
    "     overall characteristics captured in the embeddings.\n",
    "  5. Extract and display the Taxpayer IDs and similarity scores/distances of the\n",
    "     top results.\n",
    "  6. Save the query results for detailed analysis in the next notebook.\n",
    "\n",
    "**Demonstrating Value**:\n",
    "  This notebook showcases the core functionality: leveraging the unified profile\n",
    "  embeddings and vector search to proactively identify entities that resemble a\n",
    "  known 'bad' or suspicious pattern, even when that pattern requires combining\n",
    "  information from multiple original sources.\n",
    "\n",
    "**Prerequisites**:\n",
    "  - Successful completion of [Notebooks 00-05](../).\n",
    "  - Vector database populated with embeddings and IDs (via [Notebook 05](./notebook_05.ipynb)).\n",
    "  - Existence of the original synthetic data files (needed to identify the query profile based on N00 logic).\n",
    "  - Vector Database client library installed (e.g., `pip install chromadb`).\n",
    "\n",
    "**Outputs**:\n",
    "  - The Taxpayer ID of the selected query profile.\n",
    "  - A list of Taxpayer IDs for the N most similar profiles found.\n",
    "  - Corresponding similarity scores/distances.\n",
    "  - These results saved to a file (e.g., 'query_results.json').\n",
    "\n",
    "**Next Step**:\n",
    "  [Notebook 07](./notebook_07.ipynb) will analyze the original source data for these identified similar\n",
    "  profiles to see if they consistently exhibit the suspicious cross-source pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c37ec-6d5d-4ee8-8df8-1314d7641dac",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd357eca-2287-43ab-81ec-1bc00f3095b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 06: Querying for Cross-Source Similarity\n",
      "--------------------------------------------------\n",
      "Connecting to ChromaDB collection 'taxpayer_profiles' from: ./vector_db/chroma_persist\n",
      "Will query for top 10 similar profiles.\n",
      "Query profile selection criteria: Income <= 20000, Max Property Value >= 800000\n",
      "Saving results to: ./data/processed/query_results.json\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import chromadb # MVP Example Client\n",
    "import json # For saving results\n",
    "\n",
    "# --- Configuration ---\n",
    "# Vector DB / Collection Config (should match N05)\n",
    "VECTOR_DB_DIR = './vector_db'\n",
    "CHROMA_PERSIST_DIR = os.path.join(VECTOR_DB_DIR, 'chroma_persist')\n",
    "COLLECTION_NAME = \"taxpayer_profiles\"\n",
    "\n",
    "# Original Data Sources (needed to find query profile)\n",
    "DATA_DIR = './data'\n",
    "TAX_FILE_RAW = os.path.join(DATA_DIR, 'synthetic_tax_filings.csv')\n",
    "PROP_FILE_RAW = os.path.join(DATA_DIR, 'synthetic_property_ownership.csv')\n",
    "\n",
    "# Query Parameters\n",
    "# Define thresholds based on Notebook 00's fraud pattern generation\n",
    "# These values should ideally match those used in Notebook 00's configuration\n",
    "FRAUD_LOW_INCOME_MAX = 20000  # Example threshold\n",
    "FRAUD_HIGH_PROP_VALUE_MIN = 800000 # Example threshold\n",
    "N_RESULTS = 10 # Number of similar profiles to retrieve (excluding the query profile itself)\n",
    "\n",
    "# Output file\n",
    "RESULTS_OUTPUT_FILE = os.path.join('./data/processed', 'query_results.json') # Save query + results\n",
    "OUTPUT_DIR = os.path.dirname(RESULTS_OUTPUT_FILE)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) # Ensure output dir exists\n",
    "\n",
    "\n",
    "print(\"Notebook 06: Querying for Cross-Source Similarity\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Connecting to ChromaDB collection '{COLLECTION_NAME}' from: {CHROMA_PERSIST_DIR}\")\n",
    "print(f\"Will query for top {N_RESULTS} similar profiles.\")\n",
    "print(f\"Query profile selection criteria: Income <= {FRAUD_LOW_INCOME_MAX}, Max Property Value >= {FRAUD_HIGH_PROP_VALUE_MIN}\")\n",
    "print(f\"Saving results to: {RESULTS_OUTPUT_FILE}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8525b0b-05b5-49b0-95d2-94f00a601bb9",
   "metadata": {},
   "source": [
    "## Connect to Vector Database and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdccbbb3-e6a3-433b-b259-c4383830190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB Persistent Client initialized.\n",
      "Successfully connected to collection: 'taxpayer_profiles'.\n",
      "Items currently in collection: 4900\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = chromadb.PersistentClient(path=CHROMA_PERSIST_DIR)\n",
    "    print(f\"ChromaDB Persistent Client initialized.\")\n",
    "\n",
    "    # Get the existing collection\n",
    "    collection = client.get_collection(name=COLLECTION_NAME)\n",
    "    print(f\"Successfully connected to collection: '{collection.name}'.\")\n",
    "    print(f\"Items currently in collection: {collection.count()}\")\n",
    "    if collection.count() == 0:\n",
    "         print(\"ERROR: Collection is empty. Please run Notebook 05 first.\")\n",
    "         raise ValueError(\"Collection is empty\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR connecting to ChromaDB or getting collection '{COLLECTION_NAME}': {e}\")\n",
    "    print(\"Ensure the path is correct and Notebook 05 ran successfully.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdc8cc-44a2-4896-ad78-8cdc03bb5016",
   "metadata": {},
   "source": [
    "## Identify a Suspicious Query Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5ed546-d6e7-4343-96bd-2abae533b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching original data for a profile with Income <= 20000 and owns property >= 800000...\n",
      "Loaded original tax and property data.\n",
      "Found 500 IDs with income <= 20000.\n",
      "Found 493 IDs owning property >= 800000.\n",
      "Found 141 IDs matching BOTH criteria (low income AND high property value).\n",
      "Selected Query Taxpayer ID: TXP_595479B867\n"
     ]
    }
   ],
   "source": [
    "print(f\"Searching original data for a profile with Income <= {FRAUD_LOW_INCOME_MAX} and owns property >= {FRAUD_HIGH_PROP_VALUE_MIN}...\")\n",
    "\n",
    "try:\n",
    "    # Load original source data\n",
    "    tax_df_raw = pd.read_csv(TAX_FILE_RAW)\n",
    "    prop_df_raw = pd.read_csv(PROP_FILE_RAW)\n",
    "    print(\"Loaded original tax and property data.\")\n",
    "\n",
    "    # Find IDs with low income\n",
    "    low_income_ids = set(tax_df_raw[tax_df_raw['Declared Income'] <= FRAUD_LOW_INCOME_MAX]['Taxpayer ID'].astype(str))\n",
    "    print(f\"Found {len(low_income_ids)} IDs with income <= {FRAUD_LOW_INCOME_MAX}.\")\n",
    "\n",
    "    # Find IDs with high property value (check max value if multiple properties)\n",
    "    high_value_prop_ids = set(prop_df_raw[prop_df_raw['Property Value'] >= FRAUD_HIGH_PROP_VALUE_MIN]['Taxpayer ID'].astype(str))\n",
    "    print(f\"Found {len(high_value_prop_ids)} IDs owning property >= {FRAUD_HIGH_PROP_VALUE_MIN}.\")\n",
    "\n",
    "    # Find IDs present in BOTH sets (intersection)\n",
    "    suspicious_ids = list(low_income_ids.intersection(high_value_prop_ids))\n",
    "    print(f\"Found {len(suspicious_ids)} IDs matching BOTH criteria (low income AND high property value).\")\n",
    "\n",
    "    if not suspicious_ids:\n",
    "        print(\"ERROR: No Taxpayer IDs found matching the specified suspicious pattern.\")\n",
    "        print(\"Check the thresholds or the data generation logic in Notebook 00.\")\n",
    "        raise ValueError(\"No matching suspicious profiles found.\")\n",
    "\n",
    "    # Select one ID as our query profile\n",
    "    # Let's check if this ID exists in our vector DB collection\n",
    "    query_taxpayer_id = None\n",
    "    available_ids_in_db = set(collection.get(include=[])['ids']) # Get all IDs efficiently\n",
    "\n",
    "    for potential_id in suspicious_ids:\n",
    "        if potential_id in available_ids_in_db:\n",
    "            query_taxpayer_id = potential_id\n",
    "            break # Use the first one found that's definitely in the DB\n",
    "\n",
    "    if query_taxpayer_id is None:\n",
    "         print(\"ERROR: None of the identified suspicious IDs were found in the vector DB collection.\")\n",
    "         print(\"This might indicate an issue with ID consistency or the indexing process.\")\n",
    "         raise ValueError(\"Identified suspicious IDs not found in vector DB.\")\n",
    "\n",
    "    print(f\"Selected Query Taxpayer ID: {query_taxpayer_id}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Could not find original synthetic data files needed to select query profile.\")\n",
    "    print(f\"Ensure '{TAX_FILE_RAW}' and '{PROP_FILE_RAW}' exist.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during query profile selection: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cafb1-974b-49b7-8cac-2cff58d30d30",
   "metadata": {},
   "source": [
    "## Retrieve Query Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a3e936-86f5-49c5-9fb9-40b2356386ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved embedding vector for ID TXP_595479B867.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Fetch the embedding for the selected Taxpayer ID\n",
    "    query_result = collection.get(\n",
    "        ids=[query_taxpayer_id],\n",
    "        include=['embeddings'] # We only need the embedding vector\n",
    "    )\n",
    "\n",
    "    # --- Debug print statements can be removed or commented out now ---\n",
    "    # print(\"--- DEBUG ---\")\n",
    "    # print(f\"Type of query_result: {type(query_result)}\")\n",
    "    # print(f\"Value of query_result:\\n{query_result}\")\n",
    "    # print(\"--- END DEBUG ---\")\n",
    "    # --- End of DEBUG lines ---\n",
    "\n",
    "    # --- New, Robust Check ---\n",
    "    # Use .get() to safely retrieve the value, defaulting to None if key missing\n",
    "    embeddings_value = query_result.get('embeddings')\n",
    "\n",
    "    # Check if embeddings_value is None or if it's an empty list/array\n",
    "    if embeddings_value is None or len(embeddings_value) == 0:\n",
    "        print(f\"ERROR: Could not retrieve a valid embedding for query ID: {query_taxpayer_id}\")\n",
    "        print(f\"Debug: Embeddings value received: {embeddings_value}\") # Show what was received\n",
    "        raise ValueError(\"Failed to retrieve valid query embedding.\")\n",
    "    # --- End New Check ---\n",
    "\n",
    "    # If the check passes, we have at least one embedding. Get the first one.\n",
    "    query_vector = embeddings_value[0]\n",
    "    print(f\"Successfully retrieved embedding vector for ID {query_taxpayer_id}.\")\n",
    "    # print(f\"Query vector (first 10 dims): {query_vector[:10]}...\") # Optional print\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR retrieving embedding from ChromaDB: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1db730-6938-43ed-9992-8cb4b6df7115",
   "metadata": {},
   "source": [
    "## Perform Similarity Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205377dd-9294-49a2-b8bb-d886d9755c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying collection 'taxpayer_profiles' to find top 10 profiles similar to ID TXP_595479B867...\n",
      "Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Querying collection '{COLLECTION_NAME}' to find top {N_RESULTS} profiles similar to ID {query_taxpayer_id}...\")\n",
    "\n",
    "try:\n",
    "    # Perform the query\n",
    "    # Request N+1 results because the query item itself is usually the most similar\n",
    "    similarity_results = collection.query(\n",
    "        query_embeddings=[query_vector], # Chroma expects a list of query embeddings\n",
    "        n_results=N_RESULTS + 1,\n",
    "        include=['distances'] # Or 'similarities' depending on metric and preference. Include 'metadatas' if you stored them.\n",
    "    )\n",
    "    print(\"Query executed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR during ChromaDB query: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668d864-0926-4d1e-9670-0956efed6be6",
   "metadata": {},
   "source": [
    "## Process and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e70c4c-a7d8-430a-b7b5-c9ae6bfea35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw results (Top 11):\n",
      "  1. ID: TXP_595479B867, Distance: 0.0000\n",
      "  2. ID: TXP_3BF21F2AE7, Distance: 0.1354\n",
      "  3. ID: TXP_BAA950F168, Distance: 0.1524\n",
      "  4. ID: TXP_D33C9D72AD, Distance: 0.1560\n",
      "  5. ID: TXP_D9351E6FD0, Distance: 0.1891\n",
      "  6. ID: TXP_2D85DCB938, Distance: 0.1900\n",
      "  7. ID: TXP_8ACB54CE81, Distance: 0.2235\n",
      "  8. ID: TXP_58584DB75E, Distance: 0.2265\n",
      "  9. ID: TXP_20B925A862, Distance: 0.2328\n",
      "  10. ID: TXP_248D37CEF3, Distance: 0.2391\n",
      "  11. ID: TXP_A2E4FF8EC6, Distance: 0.2515\n",
      "\n",
      "Query Profile ID: TXP_595479B867\n",
      "\n",
      "Top 10 Most Similar Profiles (excluding query profile):\n",
      "      Taxpayer ID  Distance\n",
      "0  TXP_3BF21F2AE7  0.135367\n",
      "1  TXP_BAA950F168  0.152423\n",
      "2  TXP_D33C9D72AD  0.156041\n",
      "3  TXP_D9351E6FD0  0.189115\n",
      "4  TXP_2D85DCB938  0.189992\n",
      "5  TXP_8ACB54CE81  0.223525\n",
      "6  TXP_58584DB75E  0.226491\n",
      "7  TXP_20B925A862  0.232777\n",
      "8  TXP_248D37CEF3  0.239142\n",
      "9  TXP_A2E4FF8EC6  0.251476\n"
     ]
    }
   ],
   "source": [
    "# The results object is a dictionary containing lists of lists (one list per query vector)\n",
    "if not similarity_results or not similarity_results.get('ids') or not similarity_results['ids'][0]:\n",
    "    print(\"Warning: Query returned no results.\")\n",
    "    similar_ids = []\n",
    "    distances = []\n",
    "else:\n",
    "    result_ids = similarity_results['ids'][0]\n",
    "    result_distances = similarity_results['distances'][0] # Or 'similarities'\n",
    "\n",
    "    print(f\"\\nRaw results (Top {N_RESULTS+1}):\")\n",
    "    for i, (res_id, dist) in enumerate(zip(result_ids, result_distances)):\n",
    "        print(f\"  {i+1}. ID: {res_id}, Distance: {dist:.4f}\")\n",
    "\n",
    "    # Filter out the query profile itself from the results\n",
    "    filtered_results = []\n",
    "    for res_id, dist in zip(result_ids, result_distances):\n",
    "        if res_id != query_taxpayer_id:\n",
    "            filtered_results.append({'Taxpayer ID': res_id, 'Distance': dist})\n",
    "\n",
    "    # Keep only the top N results after filtering\n",
    "    top_n_similar = filtered_results[:N_RESULTS]\n",
    "\n",
    "    print(f\"\\nQuery Profile ID: {query_taxpayer_id}\")\n",
    "    print(f\"\\nTop {len(top_n_similar)} Most Similar Profiles (excluding query profile):\")\n",
    "    if top_n_similar:\n",
    "        results_df = pd.DataFrame(top_n_similar)\n",
    "        print(results_df)\n",
    "        similar_ids = results_df['Taxpayer ID'].tolist()\n",
    "        distances = results_df['Distance'].tolist()\n",
    "    else:\n",
    "        print(\"No other similar profiles found within the requested limit.\")\n",
    "        similar_ids = []\n",
    "        distances = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b0ebf-7cde-4a22-a67d-cce4d132c4f2",
   "metadata": {},
   "source": [
    "## Save Query Results for Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ce62a9-12cc-492a-a2e6-a50302e9cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved query ID and similar profile results to: ./data/processed/query_results.json\n"
     ]
    }
   ],
   "source": [
    "query_output = {\n",
    "    'query_taxpayer_id': query_taxpayer_id,\n",
    "    'similar_profiles': top_n_similar # List of dictionaries [{'Taxpayer ID': id, 'Distance': dist}, ...]\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open(RESULTS_OUTPUT_FILE, 'w') as f:\n",
    "        json.dump(query_output, f, indent=4)\n",
    "    print(f\"Successfully saved query ID and similar profile results to: {RESULTS_OUTPUT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving query results to JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902cb85-f19e-4cb6-ba1e-106cdb769639",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b332545-5583-4725-9c62-173f8bcd63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 06 finished.\n",
      "  - Identified a query profile (TXP_595479B867) exhibiting suspicious cross-source patterns.\n",
      "  - Retrieved its embedding and queried the vector database.\n",
      "  - Found the top 10 similar profiles based on embedding similarity.\n",
      "  - Saved the query ID and results for further analysis.\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook 06 finished.\")\n",
    "print(f\"  - Identified a query profile ({query_taxpayer_id}) exhibiting suspicious cross-source patterns.\")\n",
    "print(f\"  - Retrieved its embedding and queried the vector database.\")\n",
    "print(f\"  - Found the top {len(similar_ids)} similar profiles based on embedding similarity.\")\n",
    "print(\"  - Saved the query ID and results for further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668476b-0e4b-4cd9-8a9c-455b8b1cb708",
   "metadata": {},
   "source": [
    "Ready to proceed to [Notebook 07](./notebook_07.ipynb): Analyzing Cross-Source Patterns in Similar Profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ed22b-5dfa-4f21-92f2-2c9ef94c7264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
