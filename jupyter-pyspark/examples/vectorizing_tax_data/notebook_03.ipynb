{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49ba3e9-14fc-449e-9eea-5e34f13629b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 03: Feature Engineering on Unified Profiles\n",
      "--------------------------------------------------\n",
      "Loading unified profiles from: ./data/processed/unified_taxpayer_profiles.csv\n",
      "Saving engineered features to: ./data/processed/engineered_features.csv\n",
      "Saving taxpayer IDs to: ./data/processed/taxpayer_ids.csv\n",
      "--------------------------------------------------\n",
      "\n",
      "[1. Loading Unified Profile Data]\n",
      "Successfully loaded unified profile data: (4906, 14)\n",
      "Separated Taxpayer IDs.\n",
      "\n",
      "[2. Feature Creation]\n",
      "Engineering new features, especially cross-source interactions.\n",
      "\n",
      "--- 2.1 Imputing Base Missing Values ---\n",
      "Imputed missing values in base numerical columns using median: ['Declared Income', 'Deductions', 'prop_count', 'prop_value_total', 'prop_value_avg', 'prop_value_max', 'prop_value_min', 'prop_loc_distinct_count', 'directorship_count', 'comp_distinct_count']\n",
      "Imputed missing values in base categorical column 'Sector' with 'Unknown'.\n",
      "Imputed missing (NaT) dates in 'prop_ownership_earliest' with 1900-01-01.\n",
      "Imputed missing (NaT) dates in 'prop_ownership_latest' with 1900-01-01.\n",
      "\n",
      "--- 2.2 Engineering New Features ---\n",
      "Created ratio features.\n",
      "Created date-based features (ownership span, days since latest).\n",
      "\n",
      "--- 2.3 Imputing Derived Feature Missing Values ---\n",
      "No NaNs found in newly created numerical features.\n",
      "\n",
      "[3. Encode Categorical Features]\n",
      "One-Hot Encoding categorical columns: ['Sector']\n",
      "Added 10 one-hot encoded columns. Dropped original categorical columns.\n",
      "Shape after encoding: (4906, 30)\n",
      "\n",
      "[4. Scale Numerical Features]\n",
      "Scaling 28 numerical features using StandardScaler.\n",
      "Dropped original date columns: ['prop_ownership_earliest', 'prop_ownership_latest']\n",
      "Numerical features scaled to have zero mean and unit variance.\n",
      "Sample scaled data description:\n",
      "       Declared Income  Deductions  prop_count  prop_value_total  \\\n",
      "count          4906.00     4906.00     4906.00           4906.00   \n",
      "mean             -0.00       -0.00        0.00              0.00   \n",
      "std               1.00        1.00        1.00              1.00   \n",
      "min              -1.16       -1.11       -0.83             -0.58   \n",
      "25%              -0.71       -0.67       -0.83             -0.58   \n",
      "50%              -0.31       -0.32        0.06             -0.46   \n",
      "75%               0.38        0.31        0.94              0.19   \n",
      "max               2.99        6.04        5.38             10.87   \n",
      "\n",
      "       prop_value_avg  prop_value_max  prop_value_min  \\\n",
      "count         4906.00         4906.00         4906.00   \n",
      "mean            -0.00           -0.00           -0.00   \n",
      "std              1.00            1.00            1.00   \n",
      "min             -1.09           -1.11           -0.78   \n",
      "25%             -0.27           -0.30           -0.27   \n",
      "50%             -0.22           -0.25           -0.22   \n",
      "75%             -0.16           -0.18           -0.17   \n",
      "max              7.39            5.46            8.20   \n",
      "\n",
      "       prop_loc_distinct_count  directorship_count  comp_distinct_count  ...  \\\n",
      "count                  4906.00             4906.00              4906.00  ...   \n",
      "mean                      0.00                0.00                 0.00  ...   \n",
      "std                       1.00                1.00                 1.00  ...   \n",
      "min                      -0.87               -0.29                -0.29  ...   \n",
      "25%                      -0.87               -0.29                -0.29  ...   \n",
      "50%                       0.16               -0.29                -0.29  ...   \n",
      "75%                       0.16               -0.29                -0.29  ...   \n",
      "max                       4.29                8.39                 8.41  ...   \n",
      "\n",
      "       Sector_Construction  Sector_Education  Sector_Finance  \\\n",
      "count              4906.00           4906.00         4906.00   \n",
      "mean                  0.00             -0.00            0.00   \n",
      "std                   1.00              1.00            1.00   \n",
      "min                  -0.32             -0.27           -0.33   \n",
      "25%                  -0.32             -0.27           -0.33   \n",
      "50%                  -0.32             -0.27           -0.33   \n",
      "75%                  -0.32             -0.27           -0.33   \n",
      "max                   3.11              3.71            3.04   \n",
      "\n",
      "       Sector_Healthcare  Sector_Manufacturing  Sector_Other  Sector_Retail  \\\n",
      "count            4906.00               4906.00       4906.00        4906.00   \n",
      "mean                0.00                  0.00          0.00          -0.00   \n",
      "std                 1.00                  1.00          1.00           1.00   \n",
      "min                -0.35                 -0.28         -0.22          -0.41   \n",
      "25%                -0.35                 -0.28         -0.22          -0.41   \n",
      "50%                -0.35                 -0.28         -0.22          -0.41   \n",
      "75%                -0.35                 -0.28         -0.22          -0.41   \n",
      "max                 2.86                  3.64          4.56           2.45   \n",
      "\n",
      "       Sector_Services  Sector_Technology  Sector_Unknown  \n",
      "count          4906.00            4906.00         4906.00  \n",
      "mean              0.00               0.00           -0.00  \n",
      "std               1.00               1.00            1.00  \n",
      "min              -0.45              -0.41           -0.25  \n",
      "25%              -0.45              -0.41           -0.25  \n",
      "50%              -0.45              -0.41           -0.25  \n",
      "75%              -0.45              -0.41           -0.25  \n",
      "max               2.21               2.46            3.93  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "\n",
      "[5. Final Feature Selection & Inspection]\n",
      "Final check: No missing values found in the feature set.\n",
      "\n",
      "Final Engineered Features DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4906 entries, 0 to 4905\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Declared Income              4906 non-null   float64\n",
      " 1   Deductions                   4906 non-null   float64\n",
      " 2   prop_count                   4906 non-null   float64\n",
      " 3   prop_value_total             4906 non-null   float64\n",
      " 4   prop_value_avg               4906 non-null   float64\n",
      " 5   prop_value_max               4906 non-null   float64\n",
      " 6   prop_value_min               4906 non-null   float64\n",
      " 7   prop_loc_distinct_count      4906 non-null   float64\n",
      " 8   directorship_count           4906 non-null   float64\n",
      " 9   comp_distinct_count          4906 non-null   float64\n",
      " 10  income_per_prop_value_total  4906 non-null   float64\n",
      " 11  prop_value_total_per_income  4906 non-null   float64\n",
      " 12  deduction_ratio              4906 non-null   float64\n",
      " 13  prop_value_avg_per_prop      4906 non-null   float64\n",
      " 14  directorships_per_income     4906 non-null   float64\n",
      " 15  income_per_directorship      4906 non-null   float64\n",
      " 16  prop_ownership_span_days     4906 non-null   float64\n",
      " 17  prop_days_since_latest       4906 non-null   float64\n",
      " 18  Sector_Construction          4906 non-null   float64\n",
      " 19  Sector_Education             4906 non-null   float64\n",
      " 20  Sector_Finance               4906 non-null   float64\n",
      " 21  Sector_Healthcare            4906 non-null   float64\n",
      " 22  Sector_Manufacturing         4906 non-null   float64\n",
      " 23  Sector_Other                 4906 non-null   float64\n",
      " 24  Sector_Retail                4906 non-null   float64\n",
      " 25  Sector_Services              4906 non-null   float64\n",
      " 26  Sector_Technology            4906 non-null   float64\n",
      " 27  Sector_Unknown               4906 non-null   float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 1.0 MB\n",
      "\n",
      "First 5 rows of final features:\n",
      "   Declared Income  Deductions  prop_count  prop_value_total  prop_value_avg  \\\n",
      "0         2.990028    3.752137    1.828895          0.716090       -0.246165   \n",
      "1         1.242153    1.241963   -0.831218         -0.584093       -0.221618   \n",
      "2        -0.413438   -0.196272    0.055487          0.166885        0.503720   \n",
      "3        -0.562726   -0.156393   -0.831218         -0.584093       -0.221618   \n",
      "4        -0.661776   -0.885219    0.055487         -0.218229       -0.405619   \n",
      "\n",
      "   prop_value_max  prop_value_min  prop_loc_distinct_count  \\\n",
      "0       -0.100092       -0.646172                 2.224952   \n",
      "1       -0.245723       -0.219293                -0.865831   \n",
      "2        0.125289        0.904591                 0.164430   \n",
      "3       -0.245723       -0.219293                -0.865831   \n",
      "4       -0.577894       -0.057969                 0.164430   \n",
      "\n",
      "   directorship_count  comp_distinct_count  ...  Sector_Construction  \\\n",
      "0           -0.292075            -0.292320  ...            -0.322044   \n",
      "1           -0.292075            -0.292320  ...            -0.322044   \n",
      "2            6.655414             6.669447  ...            -0.322044   \n",
      "3           -0.292075            -0.292320  ...            -0.322044   \n",
      "4           -0.292075            -0.292320  ...            -0.322044   \n",
      "\n",
      "   Sector_Education  Sector_Finance  Sector_Healthcare  Sector_Manufacturing  \\\n",
      "0         -0.269414       -0.328557          -0.349487             -0.275030   \n",
      "1         -0.269414       -0.328557          -0.349487              3.635972   \n",
      "2         -0.269414       -0.328557           2.861340             -0.275030   \n",
      "3         -0.269414       -0.328557          -0.349487             -0.275030   \n",
      "4         -0.269414       -0.328557          -0.349487             -0.275030   \n",
      "\n",
      "   Sector_Other  Sector_Retail  Sector_Services  Sector_Technology  \\\n",
      "0     -0.219241      -0.408637        -0.452236           2.457384   \n",
      "1     -0.219241      -0.408637        -0.452236          -0.406937   \n",
      "2     -0.219241      -0.408637        -0.452236          -0.406937   \n",
      "3     -0.219241       2.447162        -0.452236          -0.406937   \n",
      "4     -0.219241      -0.408637        -0.452236           2.457384   \n",
      "\n",
      "   Sector_Unknown  \n",
      "0       -0.254757  \n",
      "1       -0.254757  \n",
      "2       -0.254757  \n",
      "3       -0.254757  \n",
      "4       -0.254757  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Final feature set shape: (4906, 28) (Rows, Features)\n",
      "\n",
      "[6. Save Processed Features and IDs]\n",
      "Successfully saved engineered features to: ./data/processed/engineered_features.csv\n",
      "Successfully saved Taxpayer IDs to: ./data/processed/taxpayer_ids.csv\n",
      "--------------------------------------------------\n",
      "\n",
      "[7. Conclusion]\n",
      "Notebook 03 finished.\n",
      "Successfully performed feature engineering on the unified profiles:\n",
      "  - Loaded unified data.\n",
      "  - Created new features (ratios, date-based interactions).\n",
      "  - Handled missing values through imputation.\n",
      "  - Encoded categorical features using One-Hot Encoding.\n",
      "  - Scaled all numerical features using StandardScaler.\n",
      "\n",
      "Final feature matrix shape: (4906, 28)\n",
      "The processed feature set and corresponding IDs are saved.\n",
      "\n",
      "Ready to proceed to Notebook 04: Generating Unified Profile Vector Embeddings.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Notebook 03: Feature Engineering on Unified Profiles\n",
    "\n",
    "Purpose:\n",
    "  1. Load the unified taxpayer profile data created in Notebook 02.\n",
    "  2. Select relevant base features and engineer new features, focusing on those\n",
    "     that capture cross-source interactions potentially indicative of fraud\n",
    "     (e.g., income vs. property value ratios).\n",
    "  3. Handle missing values that remain after joining and aggregation (e.g.,\n",
    "     imputing based on column type or meaning).\n",
    "  4. Encode categorical features (e.g., Sector) into a numerical format.\n",
    "  5. Scale numerical features to ensure they are suitable for distance-based\n",
    "     similarity calculations or embedding model inputs.\n",
    "  6. Produce a final DataFrame containing only the engineered, numerical features\n",
    "     ready for embedding in the next notebook.\n",
    "\n",
    "Prerequisites:\n",
    "  - Successful completion of Notebook 02.\n",
    "  - Existence of the unified profile file: 'unified_taxpayer_profiles.csv'.\n",
    "\n",
    "Outputs:\n",
    "  - A Pandas DataFrame containing the final, processed features ready for embedding.\n",
    "  - This DataFrame saved to a CSV file (e.g., 'engineered_features.csv').\n",
    "  - The corresponding Taxpayer IDs saved separately (e.g., 'taxpayer_ids.csv').\n",
    "\n",
    "Next Step:\n",
    "  Notebook 04 will use the engineered features to generate vector embeddings.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- Configuration ---\n",
    "PROCESSED_DATA_DIR = './data/processed' # Directory containing N02 output\n",
    "OUTPUT_DIR = './data/processed' # Directory to save engineered features\n",
    "\n",
    "UNIFIED_PROFILE_FILE = os.path.join(PROCESSED_DATA_DIR, 'unified_taxpayer_profiles.csv')\n",
    "FEATURES_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'engineered_features.csv')\n",
    "IDS_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'taxpayer_ids.csv')\n",
    "\n",
    "# Create output directory if it doesn't exist (should exist from N02, but check)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Get current date for calculating durations - use fixed date for reproducibility if needed\n",
    "# CURRENT_DATE = pd.to_datetime('2025-04-22') # Example fixed date\n",
    "CURRENT_DATE = pd.to_datetime(datetime.now())\n",
    "\n",
    "\n",
    "print(\"Notebook 03: Feature Engineering on Unified Profiles\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Loading unified profiles from: {UNIFIED_PROFILE_FILE}\")\n",
    "print(f\"Saving engineered features to: {FEATURES_OUTPUT_FILE}\")\n",
    "print(f\"Saving taxpayer IDs to: {IDS_OUTPUT_FILE}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Load Unified Profile Data\n",
    "# =============================================================================\n",
    "print(\"\\n[1. Loading Unified Profile Data]\")\n",
    "\n",
    "try:\n",
    "    unified_df = pd.read_csv(UNIFIED_PROFILE_FILE)\n",
    "    # Infer datetime columns if they were saved as strings\n",
    "    date_cols = ['prop_ownership_earliest', 'prop_ownership_latest']\n",
    "    for col in date_cols:\n",
    "        if col in unified_df.columns:\n",
    "            unified_df[col] = pd.to_datetime(unified_df[col], errors='coerce')\n",
    "    print(f\"Successfully loaded unified profile data: {unified_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Unified profile file not found at {UNIFIED_PROFILE_FILE}.\")\n",
    "    print(\"Please ensure Notebook 02 was run successfully and saved the file.\")\n",
    "    raise\n",
    "\n",
    "# Keep Taxpayer ID separate early on\n",
    "if 'Taxpayer ID' not in unified_df.columns:\n",
    "     print(\"ERROR: 'Taxpayer ID' column not found in the unified profile data.\")\n",
    "     raise KeyError(\"'Taxpayer ID' column missing\")\n",
    "\n",
    "taxpayer_ids = unified_df['Taxpayer ID'].copy()\n",
    "features_df = unified_df.drop(columns=['Taxpayer ID']).copy()\n",
    "print(\"Separated Taxpayer IDs.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Feature Creation\n",
    "# =============================================================================\n",
    "print(\"\\n[2. Feature Creation]\")\n",
    "print(\"Engineering new features, especially cross-source interactions.\")\n",
    "\n",
    "# --- Define columns for easier handling ---\n",
    "# Base numerical columns (potentially needing imputation before use in ratios)\n",
    "base_numeric_cols = [\n",
    "    'Declared Income', 'Deductions', 'prop_count', 'prop_value_total',\n",
    "    'prop_value_avg', 'prop_value_max', 'prop_value_min', 'prop_loc_distinct_count',\n",
    "    'directorship_count', 'comp_distinct_count'\n",
    "]\n",
    "# Ensure only existing columns are included (directorship might be optional)\n",
    "base_numeric_cols = [col for col in base_numeric_cols if col in features_df.columns]\n",
    "\n",
    "# Base categorical\n",
    "base_categorical_cols = ['Sector'] # Add more if exist\n",
    "base_categorical_cols = [col for col in base_categorical_cols if col in features_df.columns]\n",
    "\n",
    "# Base date cols\n",
    "base_date_cols = ['prop_ownership_earliest', 'prop_ownership_latest']\n",
    "base_date_cols = [col for col in base_date_cols if col in features_df.columns]\n",
    "\n",
    "# --- Handle Missing Values in Base Columns FIRST ---\n",
    "# This is important before creating ratios/derived features\n",
    "\n",
    "print(\"\\n--- 2.1 Imputing Base Missing Values ---\")\n",
    "# Impute numerical columns with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "features_df[base_numeric_cols] = num_imputer.fit_transform(features_df[base_numeric_cols])\n",
    "print(f\"Imputed missing values in base numerical columns using median: {base_numeric_cols}\")\n",
    "\n",
    "# Impute categorical columns with 'Unknown' (or most frequent)\n",
    "# Using fillna for simplicity here, SimpleImputer(strategy='most_frequent' or 'constant') is also good\n",
    "for col in base_categorical_cols:\n",
    "    fill_val = 'Unknown'\n",
    "    features_df[col] = features_df[col].fillna(fill_val)\n",
    "    print(f\"Imputed missing values in base categorical column '{col}' with '{fill_val}'.\")\n",
    "\n",
    "# Impute date columns (e.g., with a placeholder or median date if appropriate)\n",
    "# NaT dates were likely filled with a placeholder in N01/N02, let's check.\n",
    "# If we filled NaT with 1900-01-01, they are not technically NaN anymore.\n",
    "# If NaTs still exist, we need to handle them before calculating durations.\n",
    "for col in base_date_cols:\n",
    "    if features_df[col].isnull().any():\n",
    "        # Example: fill with the median date (requires calculating median first)\n",
    "        # median_date = features_df[col].median()\n",
    "        # features_df[col] = features_df[col].fillna(median_date)\n",
    "        # Or fill with a placeholder\n",
    "        placeholder_date = pd.to_datetime('1900-01-01')\n",
    "        features_df[col] = features_df[col].fillna(placeholder_date)\n",
    "        print(f\"Imputed missing (NaT) dates in '{col}' with {placeholder_date.date()}.\")\n",
    "\n",
    "# --- Create New Features ---\n",
    "print(\"\\n--- 2.2 Engineering New Features ---\")\n",
    "\n",
    "# Ratios (handle potential division by zero)\n",
    "epsilon = 1e-6 # Small number to avoid division by zero\n",
    "\n",
    "# Income vs Property\n",
    "features_df['income_per_prop_value_total'] = features_df['Declared Income'] / (features_df['prop_value_total'] + epsilon)\n",
    "features_df['prop_value_total_per_income'] = features_df['prop_value_total'] / (features_df['Declared Income'] + epsilon)\n",
    "\n",
    "# Deductions vs Income\n",
    "features_df['deduction_ratio'] = features_df['Deductions'] / (features_df['Declared Income'] + epsilon)\n",
    "\n",
    "# Property characteristics\n",
    "features_df['prop_value_avg_per_prop'] = features_df['prop_value_total'] / (features_df['prop_count'] + epsilon)\n",
    "# Clamp ratios if needed (e.g., cap deduction_ratio at 1 or 2)\n",
    "features_df['deduction_ratio'] = features_df['deduction_ratio'].clip(lower=0, upper=2) # Example clamp\n",
    "\n",
    "# Directorships vs Income (if directorship data exists)\n",
    "if 'directorship_count' in features_df.columns:\n",
    "    features_df['directorships_per_income'] = features_df['directorship_count'] / (features_df['Declared Income'] + epsilon)\n",
    "    features_df['income_per_directorship'] = features_df['Declared Income'] / (features_df['directorship_count'] + epsilon)\n",
    "\n",
    "print(\"Created ratio features.\")\n",
    "\n",
    "# Date-based features (handle potential NaT dates if not imputed above)\n",
    "if 'prop_ownership_earliest' in features_df.columns:\n",
    "    features_df['prop_ownership_span_days'] = (features_df['prop_ownership_latest'] - features_df['prop_ownership_earliest']).dt.days\n",
    "    # Impute negative spans if latest < earliest (due to imputation/placeholders)\n",
    "    features_df.loc[features_df['prop_ownership_span_days'] < 0, 'prop_ownership_span_days'] = 0\n",
    "    # Calculate time since latest purchase\n",
    "    features_df['prop_days_since_latest'] = (CURRENT_DATE - features_df['prop_ownership_latest']).dt.days\n",
    "    features_df.loc[features_df['prop_days_since_latest'] < 0, 'prop_days_since_latest'] = 0 # Handle future dates if any\n",
    "    print(\"Created date-based features (ownership span, days since latest).\")\n",
    "\n",
    "# --- Impute NaNs in newly created features (if any resulted from calculations) ---\n",
    "print(\"\\n--- 2.3 Imputing Derived Feature Missing Values ---\")\n",
    "# For ratios, 0 might be a reasonable imputation if components were 0 or NaN\n",
    "# For durations, 0 or median might be appropriate\n",
    "new_cols = features_df.columns.difference(base_numeric_cols + base_categorical_cols + base_date_cols)\n",
    "new_numeric_cols = features_df[new_cols].select_dtypes(include=np.number).columns\n",
    "\n",
    "# Replace inf values that might result from division by epsilon\n",
    "features_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "if not features_df[new_numeric_cols].isnull().values.any():\n",
    "    print(\"No NaNs found in newly created numerical features.\")\n",
    "else:\n",
    "    print(f\"NaNs found in new numerical features: {features_df[new_numeric_cols].isnull().sum().sum()}. Imputing with median...\")\n",
    "    derived_imputer = SimpleImputer(strategy='median')\n",
    "    features_df[new_numeric_cols] = derived_imputer.fit_transform(features_df[new_numeric_cols])\n",
    "    print(\"Imputed missing values in derived numerical features using median.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Encode Categorical Features\n",
    "# =============================================================================\n",
    "print(\"\\n[3. Encode Categorical Features]\")\n",
    "\n",
    "if base_categorical_cols:\n",
    "    print(f\"One-Hot Encoding categorical columns: {base_categorical_cols}\")\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # Important for dense output\n",
    "\n",
    "    # Fit and transform\n",
    "    encoded_data = encoder.fit_transform(features_df[base_categorical_cols])\n",
    "\n",
    "    # Create a new DataFrame with encoded columns\n",
    "    encoded_df = pd.DataFrame(encoded_data, index=features_df.index, columns=encoder.get_feature_names_out(base_categorical_cols))\n",
    "\n",
    "    # Drop original categorical columns and concatenate encoded ones\n",
    "    features_df = pd.concat([features_df.drop(columns=base_categorical_cols), encoded_df], axis=1)\n",
    "    print(f\"Added {len(encoded_df.columns)} one-hot encoded columns. Dropped original categorical columns.\")\n",
    "    print(f\"Shape after encoding: {features_df.shape}\")\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Scale Numerical Features\n",
    "# =============================================================================\n",
    "print(\"\\n[4. Scale Numerical Features]\")\n",
    "\n",
    "# Identify all numerical columns (including newly encoded ones)\n",
    "# Drop any remaining non-numeric columns (like original date columns if kept)\n",
    "numerical_features = features_df.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Scaling {len(numerical_features)} numerical features using StandardScaler.\")\n",
    "\n",
    "# Remove date columns if they weren't dropped earlier and aren't needed as features\n",
    "cols_to_drop = [col for col in base_date_cols if col in features_df.columns]\n",
    "if cols_to_drop:\n",
    "     features_df = features_df.drop(columns=cols_to_drop)\n",
    "     print(f\"Dropped original date columns: {cols_to_drop}\")\n",
    "     numerical_features = [col for col in numerical_features if col not in cols_to_drop]\n",
    "\n",
    "\n",
    "# Initialize and apply scaler\n",
    "scaler = StandardScaler()\n",
    "features_df[numerical_features] = scaler.fit_transform(features_df[numerical_features])\n",
    "\n",
    "print(\"Numerical features scaled to have zero mean and unit variance.\")\n",
    "print(\"Sample scaled data description:\")\n",
    "print(features_df[numerical_features].describe().round(2))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Final Feature Selection & Inspection\n",
    "# =============================================================================\n",
    "print(\"\\n[5. Final Feature Selection & Inspection]\")\n",
    "\n",
    "# At this point, features_df should contain only the numerical features ready for embedding\n",
    "# Verify no non-numeric columns remain (except maybe index)\n",
    "non_numeric_cols = features_df.select_dtypes(exclude=np.number).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"Warning: Non-numeric columns still present: {list(non_numeric_cols)}. Dropping them.\")\n",
    "    features_df = features_df.drop(columns=non_numeric_cols)\n",
    "\n",
    "# Final check for NaNs\n",
    "if features_df.isnull().values.any():\n",
    "    print(\"ERROR: NaNs still present after processing! Check imputation steps.\")\n",
    "    print(features_df.isnull().sum()[features_df.isnull().sum() > 0])\n",
    "    # Simple final fallback: fill remaining with 0\n",
    "    # features_df.fillna(0, inplace=True)\n",
    "    # print(\"Filled remaining NaNs with 0 as a fallback.\")\n",
    "    raise ValueError(\"NaNs found in final feature set before saving.\")\n",
    "else:\n",
    "    print(\"Final check: No missing values found in the feature set.\")\n",
    "\n",
    "print(\"\\nFinal Engineered Features DataFrame Info:\")\n",
    "features_df.info()\n",
    "\n",
    "print(\"\\nFirst 5 rows of final features:\")\n",
    "print(features_df.head())\n",
    "\n",
    "print(f\"\\nFinal feature set shape: {features_df.shape} (Rows, Features)\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Save Processed Features and IDs\n",
    "# =============================================================================\n",
    "print(\"\\n[6. Save Processed Features and IDs]\")\n",
    "\n",
    "try:\n",
    "    # Save the features (without index)\n",
    "    features_df.to_csv(FEATURES_OUTPUT_FILE, index=False)\n",
    "    print(f\"Successfully saved engineered features to: {FEATURES_OUTPUT_FILE}\")\n",
    "\n",
    "    # Save the corresponding Taxpayer IDs\n",
    "    pd.DataFrame({'Taxpayer ID': taxpayer_ids}).to_csv(IDS_OUTPUT_FILE, index=False)\n",
    "    print(f\"Successfully saved Taxpayer IDs to: {IDS_OUTPUT_FILE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving processed data files: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Conclusion\n",
    "# =============================================================================\n",
    "print(\"\\n[7. Conclusion]\")\n",
    "print(\"Notebook 03 finished.\")\n",
    "print(\"Successfully performed feature engineering on the unified profiles:\")\n",
    "print(\"  - Loaded unified data.\")\n",
    "print(\"  - Created new features (ratios, date-based interactions).\")\n",
    "print(\"  - Handled missing values through imputation.\")\n",
    "print(\"  - Encoded categorical features using One-Hot Encoding.\")\n",
    "print(\"  - Scaled all numerical features using StandardScaler.\")\n",
    "print(f\"\\nFinal feature matrix shape: {features_df.shape}\")\n",
    "print(\"The processed feature set and corresponding IDs are saved.\")\n",
    "print(\"\\nReady to proceed to Notebook 04: Generating Unified Profile Vector Embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6aac46-167b-4639-865d-196412852465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
