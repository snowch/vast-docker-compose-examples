{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7854a167-e9f0-4cd4-9d5f-afff5cef5a4b",
   "metadata": {},
   "source": [
    "# Feature Engineering on Unified Profiles\n",
    "\n",
    "**Purpose**:\n",
    "  1. Load the unified taxpayer profile data created in Notebook 02.\n",
    "  2. Select relevant base features and engineer new features, focusing on those\n",
    "     that capture cross-source interactions potentially indicative of fraud\n",
    "     (e.g., income vs. property value ratios).\n",
    "  3. Handle missing values that remain after joining and aggregation (e.g.,\n",
    "     imputing based on column type or meaning).\n",
    "  4. Encode categorical features (e.g., Sector) into a numerical format.\n",
    "  5. Scale numerical features to ensure they are suitable for distance-based\n",
    "     similarity calculations or embedding model inputs.\n",
    "  6. Produce a final DataFrame containing only the engineered, numerical features\n",
    "     ready for embedding in the next notebook.\n",
    "\n",
    "**Prerequisites**:\n",
    "  - Successful completion of Notebook 02.\n",
    "  - Existence of the unified profile file: 'unified_taxpayer_profiles.csv'.\n",
    "\n",
    "**Outputs**:\n",
    "  - A Pandas DataFrame containing the final, processed features ready for embedding.\n",
    "  - This DataFrame saved to a CSV file (e.g., 'engineered_features.csv').\n",
    "  - The corresponding Taxpayer IDs saved separately (e.g., 'taxpayer_ids.csv').\n",
    "\n",
    "**Next Step**:\n",
    "  Notebook 04 will use the engineered features to generate vector embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f117eb-c7dc-4d54-b891-3a9d2d1a22fb",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b170f27a-8def-4e24-984d-ed4e34c0b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 03: Feature Engineering on Unified Profiles\n",
      "--------------------------------------------------\n",
      "Loading unified profiles from: ./data/processed/unified_taxpayer_profiles.csv\n",
      "Saving engineered features to: ./data/processed/engineered_features.csv\n",
      "Saving taxpayer IDs to: ./data/processed/taxpayer_ids.csv\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Configuration ---\n",
    "PROCESSED_DATA_DIR = './data/processed' # Directory containing N02 output\n",
    "OUTPUT_DIR = './data/processed' # Directory to save engineered features\n",
    "\n",
    "UNIFIED_PROFILE_FILE = os.path.join(PROCESSED_DATA_DIR, 'unified_taxpayer_profiles.csv')\n",
    "FEATURES_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'engineered_features.csv')\n",
    "IDS_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'taxpayer_ids.csv')\n",
    "\n",
    "# Create output directory if it doesn't exist (should exist from N02, but check)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Get current date for calculating durations - use fixed date for reproducibility if needed\n",
    "# CURRENT_DATE = pd.to_datetime('2025-04-22') # Example fixed date\n",
    "CURRENT_DATE = pd.to_datetime(datetime.now())\n",
    "\n",
    "\n",
    "print(\"Notebook 03: Feature Engineering on Unified Profiles\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Loading unified profiles from: {UNIFIED_PROFILE_FILE}\")\n",
    "print(f\"Saving engineered features to: {FEATURES_OUTPUT_FILE}\")\n",
    "print(f\"Saving taxpayer IDs to: {IDS_OUTPUT_FILE}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed6c18-2f1b-434b-b25b-60532cefbeb7",
   "metadata": {},
   "source": [
    "## Load Unified Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d292e77-25cb-4922-ae18-5d8c73c333a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded unified profile data: (4906, 14)\n",
      "Separated Taxpayer IDs.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    unified_df = pd.read_csv(UNIFIED_PROFILE_FILE)\n",
    "    # Infer datetime columns if they were saved as strings\n",
    "    date_cols = ['prop_ownership_earliest', 'prop_ownership_latest']\n",
    "    for col in date_cols:\n",
    "        if col in unified_df.columns:\n",
    "            unified_df[col] = pd.to_datetime(unified_df[col], errors='coerce')\n",
    "    print(f\"Successfully loaded unified profile data: {unified_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Unified profile file not found at {UNIFIED_PROFILE_FILE}.\")\n",
    "    print(\"Please ensure Notebook 02 was run successfully and saved the file.\")\n",
    "    raise\n",
    "\n",
    "# Keep Taxpayer ID separate early on\n",
    "if 'Taxpayer ID' not in unified_df.columns:\n",
    "     print(\"ERROR: 'Taxpayer ID' column not found in the unified profile data.\")\n",
    "     raise KeyError(\"'Taxpayer ID' column missing\")\n",
    "\n",
    "taxpayer_ids = unified_df['Taxpayer ID'].copy()\n",
    "features_df = unified_df.drop(columns=['Taxpayer ID']).copy()\n",
    "print(\"Separated Taxpayer IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197d25b-489e-4478-84e5-bb7816e7b21c",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0dee19-3a20-4a58-b258-8d80b9cbbd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering new features, especially cross-source interactions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Engineering new features, especially cross-source interactions.\")\n",
    "\n",
    "# --- Define columns for easier handling ---\n",
    "# Base numerical columns (potentially needing imputation before use in ratios)\n",
    "base_numeric_cols = [\n",
    "    'Declared Income', 'Deductions', 'prop_count', 'prop_value_total',\n",
    "    'prop_value_avg', 'prop_value_max', 'prop_value_min', 'prop_loc_distinct_count',\n",
    "    'directorship_count', 'comp_distinct_count'\n",
    "]\n",
    "# Ensure only existing columns are included (directorship might be optional)\n",
    "base_numeric_cols = [col for col in base_numeric_cols if col in features_df.columns]\n",
    "\n",
    "# Base categorical\n",
    "base_categorical_cols = ['Sector'] # Add more if exist\n",
    "base_categorical_cols = [col for col in base_categorical_cols if col in features_df.columns]\n",
    "\n",
    "# Base date cols\n",
    "base_date_cols = ['prop_ownership_earliest', 'prop_ownership_latest']\n",
    "base_date_cols = [col for col in base_date_cols if col in features_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf26ca6-1261-423a-8be2-bdb17efc302a",
   "metadata": {},
   "source": [
    "### Imputing Base Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a093606-d061-453c-878f-d2426784c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing values in base numerical columns using median: ['Declared Income', 'Deductions', 'prop_count', 'prop_value_total', 'prop_value_avg', 'prop_value_max', 'prop_value_min', 'prop_loc_distinct_count', 'directorship_count', 'comp_distinct_count']\n",
      "Imputed missing values in base categorical column 'Sector' with 'Unknown'.\n",
      "Imputed missing (NaT) dates in 'prop_ownership_earliest' with 1900-01-01.\n",
      "Imputed missing (NaT) dates in 'prop_ownership_latest' with 1900-01-01.\n"
     ]
    }
   ],
   "source": [
    "# --- Handle Missing Values in Base Columns FIRST ---\n",
    "# This is important before creating ratios/derived features\n",
    "\n",
    "# Impute numerical columns with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "features_df[base_numeric_cols] = num_imputer.fit_transform(features_df[base_numeric_cols])\n",
    "print(f\"Imputed missing values in base numerical columns using median: {base_numeric_cols}\")\n",
    "\n",
    "# Impute categorical columns with 'Unknown' (or most frequent)\n",
    "# Using fillna for simplicity here, SimpleImputer(strategy='most_frequent' or 'constant') is also good\n",
    "for col in base_categorical_cols:\n",
    "    fill_val = 'Unknown'\n",
    "    features_df[col] = features_df[col].fillna(fill_val)\n",
    "    print(f\"Imputed missing values in base categorical column '{col}' with '{fill_val}'.\")\n",
    "\n",
    "# Impute date columns (e.g., with a placeholder or median date if appropriate)\n",
    "# NaT dates were likely filled with a placeholder in N01/N02, let's check.\n",
    "# If we filled NaT with 1900-01-01, they are not technically NaN anymore.\n",
    "# If NaTs still exist, we need to handle them before calculating durations.\n",
    "for col in base_date_cols:\n",
    "    if features_df[col].isnull().any():\n",
    "        # Example: fill with the median date (requires calculating median first)\n",
    "        # median_date = features_df[col].median()\n",
    "        # features_df[col] = features_df[col].fillna(median_date)\n",
    "        # Or fill with a placeholder\n",
    "        placeholder_date = pd.to_datetime('1900-01-01')\n",
    "        features_df[col] = features_df[col].fillna(placeholder_date)\n",
    "        print(f\"Imputed missing (NaT) dates in '{col}' with {placeholder_date.date()}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e3d98-9d92-40a1-8510-40f49cc147df",
   "metadata": {},
   "source": [
    "### Engineering New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d6d590-ee84-48a3-9954-8b510959ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ratio features.\n",
      "Created date-based features (ownership span, days since latest).\n"
     ]
    }
   ],
   "source": [
    "# Ratios (handle potential division by zero)\n",
    "epsilon = 1e-6 # Small number to avoid division by zero\n",
    "\n",
    "# Income vs Property\n",
    "features_df['income_per_prop_value_total'] = features_df['Declared Income'] / (features_df['prop_value_total'] + epsilon)\n",
    "features_df['prop_value_total_per_income'] = features_df['prop_value_total'] / (features_df['Declared Income'] + epsilon)\n",
    "\n",
    "# Deductions vs Income\n",
    "features_df['deduction_ratio'] = features_df['Deductions'] / (features_df['Declared Income'] + epsilon)\n",
    "\n",
    "# Property characteristics\n",
    "features_df['prop_value_avg_per_prop'] = features_df['prop_value_total'] / (features_df['prop_count'] + epsilon)\n",
    "# Clamp ratios if needed (e.g., cap deduction_ratio at 1 or 2)\n",
    "features_df['deduction_ratio'] = features_df['deduction_ratio'].clip(lower=0, upper=2) # Example clamp\n",
    "\n",
    "# Directorships vs Income (if directorship data exists)\n",
    "if 'directorship_count' in features_df.columns:\n",
    "    features_df['directorships_per_income'] = features_df['directorship_count'] / (features_df['Declared Income'] + epsilon)\n",
    "    features_df['income_per_directorship'] = features_df['Declared Income'] / (features_df['directorship_count'] + epsilon)\n",
    "\n",
    "print(\"Created ratio features.\")\n",
    "\n",
    "# Date-based features (handle potential NaT dates if not imputed above)\n",
    "if 'prop_ownership_earliest' in features_df.columns:\n",
    "    features_df['prop_ownership_span_days'] = (features_df['prop_ownership_latest'] - features_df['prop_ownership_earliest']).dt.days\n",
    "    # Impute negative spans if latest < earliest (due to imputation/placeholders)\n",
    "    features_df.loc[features_df['prop_ownership_span_days'] < 0, 'prop_ownership_span_days'] = 0\n",
    "    # Calculate time since latest purchase\n",
    "    features_df['prop_days_since_latest'] = (CURRENT_DATE - features_df['prop_ownership_latest']).dt.days\n",
    "    features_df.loc[features_df['prop_days_since_latest'] < 0, 'prop_days_since_latest'] = 0 # Handle future dates if any\n",
    "    print(\"Created date-based features (ownership span, days since latest).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32737f-00ad-465c-b8bd-1fabc7c8b41c",
   "metadata": {},
   "source": [
    "### Imputing Derived Feature Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e186eeac-5bc3-4c1e-91f6-12880c60aa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaNs found in newly created numerical features.\n"
     ]
    }
   ],
   "source": [
    "# For ratios, 0 might be a reasonable imputation if components were 0 or NaN\n",
    "# For durations, 0 or median might be appropriate\n",
    "new_cols = features_df.columns.difference(base_numeric_cols + base_categorical_cols + base_date_cols)\n",
    "new_numeric_cols = features_df[new_cols].select_dtypes(include=np.number).columns\n",
    "\n",
    "# Replace inf values that might result from division by epsilon\n",
    "features_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "if not features_df[new_numeric_cols].isnull().values.any():\n",
    "    print(\"No NaNs found in newly created numerical features.\")\n",
    "else:\n",
    "    print(f\"NaNs found in new numerical features: {features_df[new_numeric_cols].isnull().sum().sum()}. Imputing with median...\")\n",
    "    derived_imputer = SimpleImputer(strategy='median')\n",
    "    features_df[new_numeric_cols] = derived_imputer.fit_transform(features_df[new_numeric_cols])\n",
    "    print(\"Imputed missing values in derived numerical features using median.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5028e-d845-42a6-96d9-a88dc698e235",
   "metadata": {},
   "source": [
    "## Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ece926-dee3-47de-ada3-1a2f7abfa6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding categorical columns: ['Sector']\n",
      "Added 10 one-hot encoded columns. Dropped original categorical columns.\n",
      "Shape after encoding: (4906, 30)\n"
     ]
    }
   ],
   "source": [
    "if base_categorical_cols:\n",
    "    print(f\"One-Hot Encoding categorical columns: {base_categorical_cols}\")\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # Important for dense output\n",
    "\n",
    "    # Fit and transform\n",
    "    encoded_data = encoder.fit_transform(features_df[base_categorical_cols])\n",
    "\n",
    "    # Create a new DataFrame with encoded columns\n",
    "    encoded_df = pd.DataFrame(encoded_data, index=features_df.index, columns=encoder.get_feature_names_out(base_categorical_cols))\n",
    "\n",
    "    # Drop original categorical columns and concatenate encoded ones\n",
    "    features_df = pd.concat([features_df.drop(columns=base_categorical_cols), encoded_df], axis=1)\n",
    "    print(f\"Added {len(encoded_df.columns)} one-hot encoded columns. Dropped original categorical columns.\")\n",
    "    print(f\"Shape after encoding: {features_df.shape}\")\n",
    "else:\n",
    "    print(\"No categorical columns found to encode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300be6d6-a2af-4921-b249-f7edc4496b70",
   "metadata": {},
   "source": [
    "## Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6ff0b7-f88e-429a-93d4-702153efde4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling 28 numerical features using StandardScaler.\n",
      "Dropped original date columns: ['prop_ownership_earliest', 'prop_ownership_latest']\n",
      "Numerical features scaled to have zero mean and unit variance.\n",
      "Sample scaled data description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Declared Income</th>\n",
       "      <th>Deductions</th>\n",
       "      <th>prop_count</th>\n",
       "      <th>prop_value_total</th>\n",
       "      <th>prop_value_avg</th>\n",
       "      <th>prop_value_max</th>\n",
       "      <th>prop_value_min</th>\n",
       "      <th>prop_loc_distinct_count</th>\n",
       "      <th>directorship_count</th>\n",
       "      <th>comp_distinct_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Sector_Construction</th>\n",
       "      <th>Sector_Education</th>\n",
       "      <th>Sector_Finance</th>\n",
       "      <th>Sector_Healthcare</th>\n",
       "      <th>Sector_Manufacturing</th>\n",
       "      <th>Sector_Other</th>\n",
       "      <th>Sector_Retail</th>\n",
       "      <th>Sector_Services</th>\n",
       "      <th>Sector_Technology</th>\n",
       "      <th>Sector_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "      <td>4906.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.16</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.99</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5.38</td>\n",
       "      <td>10.87</td>\n",
       "      <td>7.39</td>\n",
       "      <td>5.46</td>\n",
       "      <td>8.20</td>\n",
       "      <td>4.29</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.41</td>\n",
       "      <td>...</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.64</td>\n",
       "      <td>4.56</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.46</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Declared Income  Deductions  prop_count  prop_value_total  \\\n",
       "count          4906.00     4906.00     4906.00           4906.00   \n",
       "mean             -0.00       -0.00        0.00              0.00   \n",
       "std               1.00        1.00        1.00              1.00   \n",
       "min              -1.16       -1.11       -0.83             -0.58   \n",
       "25%              -0.71       -0.67       -0.83             -0.58   \n",
       "50%              -0.31       -0.32        0.06             -0.46   \n",
       "75%               0.38        0.31        0.94              0.19   \n",
       "max               2.99        6.04        5.38             10.87   \n",
       "\n",
       "       prop_value_avg  prop_value_max  prop_value_min  \\\n",
       "count         4906.00         4906.00         4906.00   \n",
       "mean            -0.00           -0.00           -0.00   \n",
       "std              1.00            1.00            1.00   \n",
       "min             -1.09           -1.11           -0.78   \n",
       "25%             -0.27           -0.30           -0.27   \n",
       "50%             -0.22           -0.25           -0.22   \n",
       "75%             -0.16           -0.18           -0.17   \n",
       "max              7.39            5.46            8.20   \n",
       "\n",
       "       prop_loc_distinct_count  directorship_count  comp_distinct_count  ...  \\\n",
       "count                  4906.00             4906.00              4906.00  ...   \n",
       "mean                      0.00                0.00                 0.00  ...   \n",
       "std                       1.00                1.00                 1.00  ...   \n",
       "min                      -0.87               -0.29                -0.29  ...   \n",
       "25%                      -0.87               -0.29                -0.29  ...   \n",
       "50%                       0.16               -0.29                -0.29  ...   \n",
       "75%                       0.16               -0.29                -0.29  ...   \n",
       "max                       4.29                8.39                 8.41  ...   \n",
       "\n",
       "       Sector_Construction  Sector_Education  Sector_Finance  \\\n",
       "count              4906.00           4906.00         4906.00   \n",
       "mean                  0.00             -0.00            0.00   \n",
       "std                   1.00              1.00            1.00   \n",
       "min                  -0.32             -0.27           -0.33   \n",
       "25%                  -0.32             -0.27           -0.33   \n",
       "50%                  -0.32             -0.27           -0.33   \n",
       "75%                  -0.32             -0.27           -0.33   \n",
       "max                   3.11              3.71            3.04   \n",
       "\n",
       "       Sector_Healthcare  Sector_Manufacturing  Sector_Other  Sector_Retail  \\\n",
       "count            4906.00               4906.00       4906.00        4906.00   \n",
       "mean                0.00                  0.00          0.00          -0.00   \n",
       "std                 1.00                  1.00          1.00           1.00   \n",
       "min                -0.35                 -0.28         -0.22          -0.41   \n",
       "25%                -0.35                 -0.28         -0.22          -0.41   \n",
       "50%                -0.35                 -0.28         -0.22          -0.41   \n",
       "75%                -0.35                 -0.28         -0.22          -0.41   \n",
       "max                 2.86                  3.64          4.56           2.45   \n",
       "\n",
       "       Sector_Services  Sector_Technology  Sector_Unknown  \n",
       "count          4906.00            4906.00         4906.00  \n",
       "mean              0.00               0.00           -0.00  \n",
       "std               1.00               1.00            1.00  \n",
       "min              -0.45              -0.41           -0.25  \n",
       "25%              -0.45              -0.41           -0.25  \n",
       "50%              -0.45              -0.41           -0.25  \n",
       "75%              -0.45              -0.41           -0.25  \n",
       "max               2.21               2.46            3.93  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify all numerical columns (including newly encoded ones)\n",
    "# Drop any remaining non-numeric columns (like original date columns if kept)\n",
    "numerical_features = features_df.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Scaling {len(numerical_features)} numerical features using StandardScaler.\")\n",
    "\n",
    "# Remove date columns if they weren't dropped earlier and aren't needed as features\n",
    "cols_to_drop = [col for col in base_date_cols if col in features_df.columns]\n",
    "if cols_to_drop:\n",
    "     features_df = features_df.drop(columns=cols_to_drop)\n",
    "     print(f\"Dropped original date columns: {cols_to_drop}\")\n",
    "     numerical_features = [col for col in numerical_features if col not in cols_to_drop]\n",
    "\n",
    "\n",
    "# Initialize and apply scaler\n",
    "scaler = StandardScaler()\n",
    "features_df[numerical_features] = scaler.fit_transform(features_df[numerical_features])\n",
    "\n",
    "print(\"Numerical features scaled to have zero mean and unit variance.\")\n",
    "print(\"Sample scaled data description:\")\n",
    "display(features_df[numerical_features].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694f4b1-8fd7-4b70-977d-32cd6647d924",
   "metadata": {},
   "source": [
    "## Final Feature Selection & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddbfa83e-cbd5-4965-8c59-1414448bd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final check: No missing values found in the feature set.\n",
      "\n",
      "Final Engineered Features DataFrame Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4906 entries, 0 to 4905\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Declared Income              4906 non-null   float64\n",
      " 1   Deductions                   4906 non-null   float64\n",
      " 2   prop_count                   4906 non-null   float64\n",
      " 3   prop_value_total             4906 non-null   float64\n",
      " 4   prop_value_avg               4906 non-null   float64\n",
      " 5   prop_value_max               4906 non-null   float64\n",
      " 6   prop_value_min               4906 non-null   float64\n",
      " 7   prop_loc_distinct_count      4906 non-null   float64\n",
      " 8   directorship_count           4906 non-null   float64\n",
      " 9   comp_distinct_count          4906 non-null   float64\n",
      " 10  income_per_prop_value_total  4906 non-null   float64\n",
      " 11  prop_value_total_per_income  4906 non-null   float64\n",
      " 12  deduction_ratio              4906 non-null   float64\n",
      " 13  prop_value_avg_per_prop      4906 non-null   float64\n",
      " 14  directorships_per_income     4906 non-null   float64\n",
      " 15  income_per_directorship      4906 non-null   float64\n",
      " 16  prop_ownership_span_days     4906 non-null   float64\n",
      " 17  prop_days_since_latest       4906 non-null   float64\n",
      " 18  Sector_Construction          4906 non-null   float64\n",
      " 19  Sector_Education             4906 non-null   float64\n",
      " 20  Sector_Finance               4906 non-null   float64\n",
      " 21  Sector_Healthcare            4906 non-null   float64\n",
      " 22  Sector_Manufacturing         4906 non-null   float64\n",
      " 23  Sector_Other                 4906 non-null   float64\n",
      " 24  Sector_Retail                4906 non-null   float64\n",
      " 25  Sector_Services              4906 non-null   float64\n",
      " 26  Sector_Technology            4906 non-null   float64\n",
      " 27  Sector_Unknown               4906 non-null   float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 1.0 MB\n",
      "None\n",
      "\n",
      "First 5 rows of final features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Declared Income</th>\n",
       "      <th>Deductions</th>\n",
       "      <th>prop_count</th>\n",
       "      <th>prop_value_total</th>\n",
       "      <th>prop_value_avg</th>\n",
       "      <th>prop_value_max</th>\n",
       "      <th>prop_value_min</th>\n",
       "      <th>prop_loc_distinct_count</th>\n",
       "      <th>directorship_count</th>\n",
       "      <th>comp_distinct_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Sector_Construction</th>\n",
       "      <th>Sector_Education</th>\n",
       "      <th>Sector_Finance</th>\n",
       "      <th>Sector_Healthcare</th>\n",
       "      <th>Sector_Manufacturing</th>\n",
       "      <th>Sector_Other</th>\n",
       "      <th>Sector_Retail</th>\n",
       "      <th>Sector_Services</th>\n",
       "      <th>Sector_Technology</th>\n",
       "      <th>Sector_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.990028</td>\n",
       "      <td>3.752137</td>\n",
       "      <td>1.828895</td>\n",
       "      <td>0.716090</td>\n",
       "      <td>-0.246165</td>\n",
       "      <td>-0.100092</td>\n",
       "      <td>-0.646172</td>\n",
       "      <td>2.224952</td>\n",
       "      <td>-0.292075</td>\n",
       "      <td>-0.292320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322044</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>-0.328557</td>\n",
       "      <td>-0.349487</td>\n",
       "      <td>-0.275030</td>\n",
       "      <td>-0.219241</td>\n",
       "      <td>-0.408637</td>\n",
       "      <td>-0.452236</td>\n",
       "      <td>2.457384</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.242153</td>\n",
       "      <td>1.241963</td>\n",
       "      <td>-0.831218</td>\n",
       "      <td>-0.584093</td>\n",
       "      <td>-0.221618</td>\n",
       "      <td>-0.245723</td>\n",
       "      <td>-0.219293</td>\n",
       "      <td>-0.865831</td>\n",
       "      <td>-0.292075</td>\n",
       "      <td>-0.292320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322044</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>-0.328557</td>\n",
       "      <td>-0.349487</td>\n",
       "      <td>3.635972</td>\n",
       "      <td>-0.219241</td>\n",
       "      <td>-0.408637</td>\n",
       "      <td>-0.452236</td>\n",
       "      <td>-0.406937</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.413438</td>\n",
       "      <td>-0.196272</td>\n",
       "      <td>0.055487</td>\n",
       "      <td>0.166885</td>\n",
       "      <td>0.503720</td>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.904591</td>\n",
       "      <td>0.164430</td>\n",
       "      <td>6.655414</td>\n",
       "      <td>6.669447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322044</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>-0.328557</td>\n",
       "      <td>2.861340</td>\n",
       "      <td>-0.275030</td>\n",
       "      <td>-0.219241</td>\n",
       "      <td>-0.408637</td>\n",
       "      <td>-0.452236</td>\n",
       "      <td>-0.406937</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.562726</td>\n",
       "      <td>-0.156393</td>\n",
       "      <td>-0.831218</td>\n",
       "      <td>-0.584093</td>\n",
       "      <td>-0.221618</td>\n",
       "      <td>-0.245723</td>\n",
       "      <td>-0.219293</td>\n",
       "      <td>-0.865831</td>\n",
       "      <td>-0.292075</td>\n",
       "      <td>-0.292320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322044</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>-0.328557</td>\n",
       "      <td>-0.349487</td>\n",
       "      <td>-0.275030</td>\n",
       "      <td>-0.219241</td>\n",
       "      <td>2.447162</td>\n",
       "      <td>-0.452236</td>\n",
       "      <td>-0.406937</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661776</td>\n",
       "      <td>-0.885219</td>\n",
       "      <td>0.055487</td>\n",
       "      <td>-0.218229</td>\n",
       "      <td>-0.405619</td>\n",
       "      <td>-0.577894</td>\n",
       "      <td>-0.057969</td>\n",
       "      <td>0.164430</td>\n",
       "      <td>-0.292075</td>\n",
       "      <td>-0.292320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322044</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>-0.328557</td>\n",
       "      <td>-0.349487</td>\n",
       "      <td>-0.275030</td>\n",
       "      <td>-0.219241</td>\n",
       "      <td>-0.408637</td>\n",
       "      <td>-0.452236</td>\n",
       "      <td>2.457384</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Declared Income  Deductions  prop_count  prop_value_total  prop_value_avg  \\\n",
       "0         2.990028    3.752137    1.828895          0.716090       -0.246165   \n",
       "1         1.242153    1.241963   -0.831218         -0.584093       -0.221618   \n",
       "2        -0.413438   -0.196272    0.055487          0.166885        0.503720   \n",
       "3        -0.562726   -0.156393   -0.831218         -0.584093       -0.221618   \n",
       "4        -0.661776   -0.885219    0.055487         -0.218229       -0.405619   \n",
       "\n",
       "   prop_value_max  prop_value_min  prop_loc_distinct_count  \\\n",
       "0       -0.100092       -0.646172                 2.224952   \n",
       "1       -0.245723       -0.219293                -0.865831   \n",
       "2        0.125289        0.904591                 0.164430   \n",
       "3       -0.245723       -0.219293                -0.865831   \n",
       "4       -0.577894       -0.057969                 0.164430   \n",
       "\n",
       "   directorship_count  comp_distinct_count  ...  Sector_Construction  \\\n",
       "0           -0.292075            -0.292320  ...            -0.322044   \n",
       "1           -0.292075            -0.292320  ...            -0.322044   \n",
       "2            6.655414             6.669447  ...            -0.322044   \n",
       "3           -0.292075            -0.292320  ...            -0.322044   \n",
       "4           -0.292075            -0.292320  ...            -0.322044   \n",
       "\n",
       "   Sector_Education  Sector_Finance  Sector_Healthcare  Sector_Manufacturing  \\\n",
       "0         -0.269414       -0.328557          -0.349487             -0.275030   \n",
       "1         -0.269414       -0.328557          -0.349487              3.635972   \n",
       "2         -0.269414       -0.328557           2.861340             -0.275030   \n",
       "3         -0.269414       -0.328557          -0.349487             -0.275030   \n",
       "4         -0.269414       -0.328557          -0.349487             -0.275030   \n",
       "\n",
       "   Sector_Other  Sector_Retail  Sector_Services  Sector_Technology  \\\n",
       "0     -0.219241      -0.408637        -0.452236           2.457384   \n",
       "1     -0.219241      -0.408637        -0.452236          -0.406937   \n",
       "2     -0.219241      -0.408637        -0.452236          -0.406937   \n",
       "3     -0.219241       2.447162        -0.452236          -0.406937   \n",
       "4     -0.219241      -0.408637        -0.452236           2.457384   \n",
       "\n",
       "   Sector_Unknown  \n",
       "0       -0.254757  \n",
       "1       -0.254757  \n",
       "2       -0.254757  \n",
       "3       -0.254757  \n",
       "4       -0.254757  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final feature set shape: (4906, 28) (Rows, Features)\n"
     ]
    }
   ],
   "source": [
    "# At this point, features_df should contain only the numerical features ready for embedding\n",
    "# Verify no non-numeric columns remain (except maybe index)\n",
    "non_numeric_cols = features_df.select_dtypes(exclude=np.number).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"Warning: Non-numeric columns still present: {list(non_numeric_cols)}. Dropping them.\")\n",
    "    features_df = features_df.drop(columns=non_numeric_cols)\n",
    "\n",
    "# Final check for NaNs\n",
    "if features_df.isnull().values.any():\n",
    "    print(\"ERROR: NaNs still present after processing! Check imputation steps.\")\n",
    "    print(features_df.isnull().sum()[features_df.isnull().sum() > 0])\n",
    "    # Simple final fallback: fill remaining with 0\n",
    "    # features_df.fillna(0, inplace=True)\n",
    "    # print(\"Filled remaining NaNs with 0 as a fallback.\")\n",
    "    raise ValueError(\"NaNs found in final feature set before saving.\")\n",
    "else:\n",
    "    print(\"Final check: No missing values found in the feature set.\")\n",
    "\n",
    "print(\"\\nFinal Engineered Features DataFrame Info:\\n\")\n",
    "print(features_df.info())\n",
    "\n",
    "print(\"\\nFirst 5 rows of final features:\")\n",
    "display(features_df.head())\n",
    "\n",
    "print(f\"\\nFinal feature set shape: {features_df.shape} (Rows, Features)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee52d86-0cd8-40dd-90bb-6bd57475491e",
   "metadata": {},
   "source": [
    "## Save Processed Features and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1993098f-7557-41eb-9811-dca0ef962a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved engineered features to: ./data/processed/engineered_features.csv\n",
      "Successfully saved Taxpayer IDs to: ./data/processed/taxpayer_ids.csv\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Save the features (without index)\n",
    "    features_df.to_csv(FEATURES_OUTPUT_FILE, index=False)\n",
    "    print(f\"Successfully saved engineered features to: {FEATURES_OUTPUT_FILE}\")\n",
    "\n",
    "    # Save the corresponding Taxpayer IDs\n",
    "    pd.DataFrame({'Taxpayer ID': taxpayer_ids}).to_csv(IDS_OUTPUT_FILE, index=False)\n",
    "    print(f\"Successfully saved Taxpayer IDs to: {IDS_OUTPUT_FILE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving processed data files: {e}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08be88b-dd1f-440a-880a-b28380f3118d",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49ba3e9-14fc-449e-9eea-5e34f13629b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 03 finished.\n",
      "Successfully performed feature engineering on the unified profiles:\n",
      "  - Loaded unified data.\n",
      "  - Created new features (ratios, date-based interactions).\n",
      "  - Handled missing values through imputation.\n",
      "  - Encoded categorical features using One-Hot Encoding.\n",
      "  - Scaled all numerical features using StandardScaler.\n",
      "\n",
      "Final feature matrix shape: (4906, 28)\n",
      "The processed feature set and corresponding IDs are saved.\n",
      "\n",
      "Ready to proceed to Notebook 04: Generating Unified Profile Vector Embeddings.\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook 03 finished.\")\n",
    "print(\"Successfully performed feature engineering on the unified profiles:\")\n",
    "print(\"  - Loaded unified data.\")\n",
    "print(\"  - Created new features (ratios, date-based interactions).\")\n",
    "print(\"  - Handled missing values through imputation.\")\n",
    "print(\"  - Encoded categorical features using One-Hot Encoding.\")\n",
    "print(\"  - Scaled all numerical features using StandardScaler.\")\n",
    "print(f\"\\nFinal feature matrix shape: {features_df.shape}\")\n",
    "print(\"The processed feature set and corresponding IDs are saved.\")\n",
    "print(\"\\nReady to proceed to Notebook 04: Generating Unified Profile Vector Embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6aac46-167b-4639-865d-196412852465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
