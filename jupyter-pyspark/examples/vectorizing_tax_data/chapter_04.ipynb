{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306cc603-86bb-4386-901c-d07f4db16c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 04: Generating Unified Profile Vector Embeddings\n",
      "--------------------------------------------------\n",
      "Loading engineered features from: ./data/processed/engineered_features.csv\n",
      "Loading taxpayer IDs from: ./data/processed/taxpayer_ids.csv\n",
      "Saving embeddings to: ./data/processed/embeddings.npy\n",
      "Saving corresponding IDs to: ./data/processed/embedding_ids.csv\n",
      "--------------------------------------------------\n",
      "\n",
      "[1. Load Processed Features and IDs]\n",
      "Successfully loaded engineered features: (4906, 28)\n",
      "Successfully loaded taxpayer IDs: (4906, 1)\n",
      "Validation: No missing values found in features.\n",
      "Validation: Number of feature rows matches number of IDs.\n",
      "\n",
      "[2. Prepare Data for Embedding Generation]\n",
      "Converted features DataFrame to NumPy array with shape: (4906, 28)\n",
      "Converted Taxpayer IDs to list. Total IDs: 4906\n",
      "Validation: Feature array rows align with ID list length.\n",
      "\n",
      "[3. Generate Embeddings]\n",
      "Using engineered feature vectors directly as embeddings.\n",
      "Generated 4906 embeddings.\n",
      "Embedding Dimension: 28\n",
      "\n",
      "[4. Inspect Embeddings]\n",
      "Shape of the final embeddings array: (4906, 28)\n",
      "Data type of embeddings: float64\n",
      "\n",
      "Sample Embeddings (first 3):\n",
      "  ID TXP_E93AF09B2C: [ 2.99002798  3.75213658  1.82889541  0.71609012 -0.24616513 -0.10009215\n",
      " -0.64617211  2.22495216 -0.29207493 -0.29232043]...\n",
      "  ID TXP_BBEF96BCCE: [ 1.24215297  1.2419631  -0.83121751 -0.58409309 -0.22161765 -0.24572348\n",
      " -0.21929311 -0.86583084 -0.29207493 -0.29232043]...\n",
      "  ID TXP_4E05F8D57D: [-0.41343806 -0.19627224  0.0554868   0.1668853   0.50371971  0.12528882\n",
      "  0.90459089  0.16443016  6.655414    6.6694466 ]...\n",
      "\n",
      "[5. Save Embeddings and Corresponding IDs]\n",
      "Saving embeddings in NumPy binary format (.npy) and IDs as CSV.\n",
      "Successfully saved embeddings NumPy array to: ./data/processed/embeddings.npy\n",
      "Successfully saved corresponding Taxpayer IDs to: ./data/processed/embedding_ids.csv\n",
      "--------------------------------------------------\n",
      "\n",
      "[6. Conclusion]\n",
      "Notebook 04 finished.\n",
      "Successfully generated vector embeddings for each unified taxpayer profile:\n",
      "  - Loaded 4906 engineered profiles.\n",
      "  - Used the 28-dimensional feature vectors directly as embeddings (MVP approach).\n",
      "  - Saved the embeddings as a NumPy array and the corresponding IDs.\n",
      "\n",
      "The embeddings are now ready for indexing in a vector database.\n",
      "\n",
      "Proceed to Notebook 05: Setting Up Vector DB & Indexing Profile Embeddings.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Notebook 04: Generating Unified Profile Vector Embeddings\n",
    "\n",
    "Purpose:\n",
    "  1. Load the final, engineered feature set and corresponding Taxpayer IDs\n",
    "     prepared in Notebook 03.\n",
    "  2. Apply a technique to represent each taxpayer's profile (defined by their\n",
    "     engineered features) as a dense vector embedding.\n",
    "     *MVP Approach*: Use the scaled feature vectors directly as embeddings.\n",
    "  3. Verify the dimensions and alignment of the generated embeddings and IDs.\n",
    "  4. Save the embeddings and corresponding Taxpayer IDs in formats suitable for\n",
    "     ingestion into a vector database in the next notebook.\n",
    "\n",
    "Why Embeddings?\n",
    "  Embeddings capture the complex, multi-faceted characteristics of each taxpayer\n",
    "  profile (derived from multiple data sources) in a numerical vector format.\n",
    "  This allows us to use efficient vector similarity search techniques to find\n",
    "  taxpayers with similar overall profiles, which is crucial for identifying\n",
    "  anomalous or potentially fraudulent patterns that might be hidden when looking\n",
    "  at features in isolation.\n",
    "\n",
    "Prerequisites:\n",
    "  - Successful completion of Notebook 03.\n",
    "  - Existence of the engineered features file ('engineered_features.csv').\n",
    "  - Existence of the corresponding Taxpayer IDs file ('taxpayer_ids.csv').\n",
    "\n",
    "Outputs:\n",
    "  - A NumPy array containing the vector embeddings (one row per taxpayer).\n",
    "  - This array saved to a file (e.g., 'embeddings.npy').\n",
    "  - The corresponding Taxpayer IDs saved alongside (e.g., 'embedding_ids.csv').\n",
    "\n",
    "Next Step:\n",
    "  Notebook 05 will set up a vector database and index these generated embeddings.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# Optional: Import PCA if demonstrating dimensionality reduction as an alternative\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Configuration ---\n",
    "PROCESSED_DATA_DIR = './data/processed' # Directory containing N03 output\n",
    "OUTPUT_DIR = './data/processed' # Directory to save embeddings and IDs\n",
    "\n",
    "FEATURES_INPUT_FILE = os.path.join(PROCESSED_DATA_DIR, 'engineered_features.csv')\n",
    "IDS_INPUT_FILE = os.path.join(PROCESSED_DATA_DIR, 'taxpayer_ids.csv')\n",
    "\n",
    "EMBEDDINGS_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'embeddings.npy')\n",
    "EMBEDDING_IDS_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'embedding_ids.csv') # Save IDs again for clarity\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Notebook 04: Generating Unified Profile Vector Embeddings\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Loading engineered features from: {FEATURES_INPUT_FILE}\")\n",
    "print(f\"Loading taxpayer IDs from: {IDS_INPUT_FILE}\")\n",
    "print(f\"Saving embeddings to: {EMBEDDINGS_OUTPUT_FILE}\")\n",
    "print(f\"Saving corresponding IDs to: {EMBEDDING_IDS_OUTPUT_FILE}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Load Processed Features and IDs\n",
    "# =============================================================================\n",
    "print(\"\\n[1. Load Processed Features and IDs]\")\n",
    "\n",
    "try:\n",
    "    features_df = pd.read_csv(FEATURES_INPUT_FILE)\n",
    "    print(f\"Successfully loaded engineered features: {features_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Engineered features file not found at {FEATURES_INPUT_FILE}.\")\n",
    "    print(\"Please ensure Notebook 03 was run successfully and saved the file.\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    taxpayer_ids_df = pd.read_csv(IDS_INPUT_FILE)\n",
    "    print(f\"Successfully loaded taxpayer IDs: {taxpayer_ids_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Taxpayer IDs file not found at {IDS_INPUT_FILE}.\")\n",
    "    print(\"Please ensure Notebook 03 was run successfully and saved the file.\")\n",
    "    raise\n",
    "\n",
    "# Basic Validation\n",
    "if features_df.isnull().values.any():\n",
    "    print(\"ERROR: Missing values found in the loaded features data!\")\n",
    "    print(features_df.isnull().sum())\n",
    "    raise ValueError(\"NaNs found in feature data. Cannot generate embeddings.\")\n",
    "else:\n",
    "    print(\"Validation: No missing values found in features.\")\n",
    "\n",
    "if len(features_df) != len(taxpayer_ids_df):\n",
    "    print(f\"ERROR: Mismatch between number of feature rows ({len(features_df)}) and number of IDs ({len(taxpayer_ids_df)})!\")\n",
    "    raise ValueError(\"Mismatch in length between features and IDs.\")\n",
    "else:\n",
    "    print(\"Validation: Number of feature rows matches number of IDs.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Prepare Data for Embedding Generation\n",
    "# =============================================================================\n",
    "print(\"\\n[2. Prepare Data for Embedding Generation]\")\n",
    "\n",
    "# Convert features DataFrame to NumPy array\n",
    "# This array represents the multi-dimensional space where each taxpayer profile exists\n",
    "features_array = features_df.to_numpy()\n",
    "print(f\"Converted features DataFrame to NumPy array with shape: {features_array.shape}\")\n",
    "\n",
    "# Ensure IDs are in a simple list format, preserving order\n",
    "id_list = taxpayer_ids_df['Taxpayer ID'].astype(str).tolist()\n",
    "print(f\"Converted Taxpayer IDs to list. Total IDs: {len(id_list)}\")\n",
    "\n",
    "# Final check for alignment\n",
    "assert features_array.shape[0] == len(id_list), \"Mismatch between feature array rows and ID list length!\"\n",
    "print(\"Validation: Feature array rows align with ID list length.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Generate Embeddings\n",
    "# =============================================================================\n",
    "print(\"\\n[3. Generate Embeddings]\")\n",
    "\n",
    "# --- MVP Approach: Use Engineered Features Directly ---\n",
    "# In this approach, the final processed feature vector for each taxpayer IS the embedding.\n",
    "# This is the simplest method and directly uses the information engineered in N03.\n",
    "# The dimensionality of the embedding will be equal to the number of features.\n",
    "\n",
    "embeddings = features_array\n",
    "embedding_dimension = embeddings.shape[1]\n",
    "\n",
    "print(f\"Using engineered feature vectors directly as embeddings.\")\n",
    "print(f\"Generated {embeddings.shape[0]} embeddings.\")\n",
    "print(f\"Embedding Dimension: {embedding_dimension}\")\n",
    "\n",
    "\n",
    "# --- Optional Alternative: Dimensionality Reduction (e.g., PCA) ---\n",
    "# If the feature dimensionality is very high, or if we want potentially smoother\n",
    "# embeddings, techniques like PCA can be used. This is not the primary path for the MVP.\n",
    "# Uncomment the following block to experiment with PCA:\n",
    "\"\"\"\n",
    "print(\"\\n--- Optional: Generating embeddings using PCA ---\")\n",
    "# Choose the number of dimensions for the PCA embedding\n",
    "PCA_DIMENSIONS = 32 # Example dimension - tune based on explained variance\n",
    "\n",
    "pca = PCA(n_components=PCA_DIMENSIONS, random_state=42)\n",
    "embeddings_pca = pca.fit_transform(features_array)\n",
    "\n",
    "print(f\"Generated PCA embeddings with shape: {embeddings_pca.shape}\")\n",
    "print(f\"Explained variance ratio by {PCA_DIMENSIONS} components: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "# If using PCA, you would replace the main 'embeddings' variable:\n",
    "# embeddings = embeddings_pca\n",
    "# embedding_dimension = PCA_DIMENSIONS\n",
    "# print(f\"NOTE: Switched to using PCA embeddings for subsequent steps.\")\n",
    "print(\"--- End Optional PCA Section ---\")\n",
    "\"\"\"\n",
    "# --- End Optional Section ---\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Inspect Embeddings\n",
    "# =============================================================================\n",
    "print(\"\\n[4. Inspect Embeddings]\")\n",
    "\n",
    "print(f\"Shape of the final embeddings array: {embeddings.shape}\")\n",
    "print(f\"Data type of embeddings: {embeddings.dtype}\")\n",
    "\n",
    "# Show the first few embeddings (or slices of them)\n",
    "print(\"\\nSample Embeddings (first 3):\")\n",
    "for i in range(min(3, len(embeddings))):\n",
    "    # Print first 10 components if dimension is large\n",
    "    print(f\"  ID {id_list[i]}: {embeddings[i][:min(10, embedding_dimension)]}...\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Save Embeddings and Corresponding IDs\n",
    "# =============================================================================\n",
    "print(\"\\n[5. Save Embeddings and Corresponding IDs]\")\n",
    "print(\"Saving embeddings in NumPy binary format (.npy) and IDs as CSV.\")\n",
    "\n",
    "try:\n",
    "    # Save the embeddings array\n",
    "    np.save(EMBEDDINGS_OUTPUT_FILE, embeddings)\n",
    "    print(f\"Successfully saved embeddings NumPy array to: {EMBEDDINGS_OUTPUT_FILE}\")\n",
    "\n",
    "    # Save the corresponding IDs (in the same order) as a CSV\n",
    "    # This makes it easy to load the IDs alongside the embeddings in the next notebook\n",
    "    ids_to_save_df = pd.DataFrame({'Taxpayer ID': id_list})\n",
    "    ids_to_save_df.to_csv(EMBEDDING_IDS_OUTPUT_FILE, index=False)\n",
    "    print(f\"Successfully saved corresponding Taxpayer IDs to: {EMBEDDING_IDS_OUTPUT_FILE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving embedding data files: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Conclusion\n",
    "# =============================================================================\n",
    "print(\"\\n[6. Conclusion]\")\n",
    "print(\"Notebook 04 finished.\")\n",
    "print(\"Successfully generated vector embeddings for each unified taxpayer profile:\")\n",
    "print(f\"  - Loaded {len(id_list)} engineered profiles.\")\n",
    "print(f\"  - Used the {embedding_dimension}-dimensional feature vectors directly as embeddings (MVP approach).\")\n",
    "print(\"  - Saved the embeddings as a NumPy array and the corresponding IDs.\")\n",
    "print(\"\\nThe embeddings are now ready for indexing in a vector database.\")\n",
    "print(\"\\nProceed to Notebook 05: Setting Up Vector DB & Indexing Profile Embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b7b48-8464-4264-89c3-2b8ca2050d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
