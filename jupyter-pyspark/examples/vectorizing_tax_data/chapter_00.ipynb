{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40089da1-3e46-4456-a114-233b85432cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. Environment Setup Instructions]\n",
      "Please ensure you have followed the environment setup steps above.\n",
      "Make sure the required libraries (pandas, numpy, etc.) are installed.\n",
      "--------------------------------------------------\n",
      "[2. Importing Libraries]\n",
      "Libraries imported successfully.\n",
      "--------------------------------------------------\n",
      "[3. Configuration for Data Generation]\n",
      "Configuration set:\n",
      "  NUM_TAXPAYERS: 5000\n",
      "  OUTPUT_DIR: ./data\n",
      "  SEED: 42\n",
      "  GENERATE_DIRECTORSHIPS: True\n",
      "  FRAUD_PATTERN_RATIO: 0.03\n",
      "--------------------------------------------------\n",
      "[4. Generating Base Taxpayer IDs]\n",
      "Generated 5000 unique Taxpayer IDs.\n",
      "--------------------------------------------------\n",
      "[5. Generating Synthetic Tax Filings Data]\n",
      "Generated initial tax filings data for 4750 taxpayers.\n",
      "Selected 150 Taxpayer IDs to embed cross-source fraud pattern.\n",
      "Modified 'Declared Income' for 150 IDs to be below $20000.00.\n",
      "Introduced ~3.0% missing values into tax data (excluding ID).\n",
      "Sample Tax Filings Data (with potential fraud pattern):\n",
      "      Taxpayer ID  Declared Income  Deductions         Sector\n",
      "0  TXP_E93AF09B2C        250000.00    48301.93     Technology\n",
      "1  TXP_BBEF96BCCE        147896.72    23505.16  Manufacturing\n",
      "2  TXP_4E05F8D57D         51184.27     9297.54     Healthcare\n",
      "3  TXP_DA149E72D1         42463.53     9691.49         Retail\n",
      "4  TXP_B25178D07C         36677.42     2491.77     Technology\n",
      "\n",
      "Example Tax Record for a 'Fraud Pattern' ID:\n",
      "         Taxpayer ID  Declared Income   Deductions   Sector\n",
      "1399  TXP_6FA8CB14F2         15238.68  2827.818406  Finance\n",
      "--------------------------------------------------\n",
      "[6. Generating Synthetic Property Ownership Data]\n",
      "Total unique property owners (including fraud pattern IDs): 3538\n",
      "Generated 4599 property records for 2578 unique owners.\n",
      "Introduced ~4.0% missing values into property data (excluding ID).\n",
      "\n",
      "Sample Property Ownership Data:\n",
      "      Taxpayer ID  Property Value       Location Ownership Date\n",
      "0  TXP_E005DB74FC       638048.78     Rural East     2010-12-18\n",
      "1  TXP_6BB4E2BC42       763041.06    City Center     2022-10-22\n",
      "2  TXP_F983E6DEC1       172513.43    City Center     2024-09-29\n",
      "3  TXP_AA5425C49D        50000.00   Coastal Area     2008-09-03\n",
      "4  TXP_5994267F54        84684.26  Suburban West     2019-02-19\n",
      "\n",
      "Example Property Record(s) for the same 'Fraud Pattern' ID:\n",
      "Empty DataFrame\n",
      "Columns: [Taxpayer ID, Property Value, Location, Ownership Date]\n",
      "Index: []\n",
      "--------------------------------------------------\n",
      "[7. Generating Synthetic Company Directorships Data (Optional)]\n",
      "Selected 750 unique taxpayers as potential directors.\n",
      "Generated 825 directorship records for 488 unique directors across 562 companies.\n",
      "Introduced ~2.0% missing values into company data (excluding ID).\n",
      "\n",
      "Sample Company Directorship Data:\n",
      "      Taxpayer ID     Company ID           Director Role\n",
      "0  TXP_DB9CBBB12A  COMP_6B0C8E32               Secretary\n",
      "1  TXP_E21452C754  COMP_9457FBA4                Director\n",
      "2  TXP_7EA64B294E  COMP_4BDA89C5                Director\n",
      "3  TXP_140DD6DAC1  COMP_3B372A06                Director\n",
      "4  TXP_B7B965FC78  COMP_AA107E1F  Non-Executive Director\n",
      "\n",
      "Example Directorship Record(s) for the same 'Fraud Pattern' ID (if they exist):\n",
      "Empty DataFrame\n",
      "Columns: [Taxpayer ID, Company ID, Director Role]\n",
      "Index: []\n",
      "--------------------------------------------------\n",
      "[8. Saving Generated Data to CSV]\n",
      "Successfully saved tax data to: ./data/synthetic_tax_filings.csv\n",
      "Successfully saved property data to: ./data/synthetic_property_ownership.csv\n",
      "Successfully saved company directorship data to: ./data/synthetic_company_directorships.csv\n",
      "--------------------------------------------------\n",
      "[9. Verification Step (Optional)]\n",
      "Quick check of generated files:\n",
      "\n",
      "Tax File (./data/synthetic_tax_filings.csv):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4750 entries, 0 to 4749\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Taxpayer ID      4750 non-null   object \n",
      " 1   Declared Income  4614 non-null   float64\n",
      " 2   Deductions       4599 non-null   float64\n",
      " 3   Sector           4607 non-null   object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 148.6+ KB\n",
      "None\n",
      "      Taxpayer ID  Declared Income  Deductions         Sector\n",
      "0  TXP_E93AF09B2C        250000.00    48301.93     Technology\n",
      "1  TXP_BBEF96BCCE        147896.72    23505.16  Manufacturing\n",
      "2  TXP_4E05F8D57D         51184.27     9297.54     Healthcare\n",
      "3  TXP_DA149E72D1         42463.53     9691.49         Retail\n",
      "4  TXP_B25178D07C         36677.42     2491.77     Technology\n",
      "\n",
      "Property File (./data/synthetic_property_ownership.csv):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4599 entries, 0 to 4598\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Taxpayer ID     4599 non-null   object \n",
      " 1   Property Value  4413 non-null   float64\n",
      " 2   Location        4423 non-null   object \n",
      " 3   Ownership Date  4418 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 143.8+ KB\n",
      "None\n",
      "      Taxpayer ID  Property Value       Location Ownership Date\n",
      "0  TXP_E005DB74FC       638048.78     Rural East     2010-12-18\n",
      "1  TXP_6BB4E2BC42       763041.06    City Center     2022-10-22\n",
      "2  TXP_F983E6DEC1       172513.43    City Center     2024-09-29\n",
      "3  TXP_AA5425C49D        50000.00   Coastal Area     2008-09-03\n",
      "4  TXP_5994267F54        84684.26  Suburban West     2019-02-19\n",
      "\n",
      "Company File (./data/synthetic_company_directorships.csv):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 825 entries, 0 to 824\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Taxpayer ID    825 non-null    object\n",
      " 1   Company ID     825 non-null    object\n",
      " 2   Director Role  813 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 19.5+ KB\n",
      "None\n",
      "      Taxpayer ID     Company ID           Director Role\n",
      "0  TXP_DB9CBBB12A  COMP_6B0C8E32               Secretary\n",
      "1  TXP_E21452C754  COMP_9457FBA4                Director\n",
      "2  TXP_7EA64B294E  COMP_4BDA89C5                Director\n",
      "3  TXP_140DD6DAC1  COMP_3B372A06                Director\n",
      "4  TXP_B7B965FC78  COMP_AA107E1F  Non-Executive Director\n",
      "\n",
      "Verifying cross-source pattern for ID: TXP_6FA8CB14F2\n",
      "Tax Record:\n",
      "         Taxpayer ID  Declared Income\n",
      "1399  TXP_6FA8CB14F2         15238.68\n",
      "\n",
      "Property Record(s):\n",
      "Empty DataFrame\n",
      "Columns: [Taxpayer ID, Property Value]\n",
      "Index: []\n",
      "\n",
      "Pattern Check -> Low Income: True, High Property Value: False\n",
      "--------------------------------------------------\n",
      "[10. Conclusion]\n",
      "Notebook 00 finished.\n",
      "Environment setup guidance provided.\n",
      "Synthetic data files generated and saved:\n",
      "  - ./data/synthetic_tax_filings.csv\n",
      "  - ./data/synthetic_property_ownership.csv\n",
      "  - ./data/synthetic_company_directorships.csv\n",
      "Data includes embedded cross-source patterns for selected 'fraudulent' profiles.\n",
      "\n",
      "Ready to proceed to Notebook 01: Source Data Exploration & Initial Cleaning.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Notebook 00: Environment Setup & Multi-Source Synthetic Data Generation\n",
    "\n",
    "Purpose:\n",
    "  1. Guide the user on setting up the required Python environment.\n",
    "  2. Generate synthetic datasets representing different sources (Tax Filings,\n",
    "     Property Ownership, optionally Company Directorships).\n",
    "  3. Ensure these datasets share common identifiers ('Taxpayer ID') for linking.\n",
    "  4. Embed plausible cross-source patterns indicative of potential fraud\n",
    "     (e.g., low declared income + high-value property ownership) for later detection.\n",
    "\n",
    "Outputs:\n",
    "  - A configured Python environment with necessary libraries.\n",
    "  - CSV files saved to the specified data directory:\n",
    "    - 'synthetic_tax_filings.csv'\n",
    "    - 'synthetic_property_ownership.csv'\n",
    "    - (Optional) 'synthetic_company_directorships.csv'\n",
    "\n",
    "Next Step:\n",
    "  Notebook 01 will load and explore these generated datasets.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Environment Setup Instructions\n",
    "# =============================================================================\n",
    "print(\"[1. Environment Setup Instructions]\")\n",
    "\n",
    "\"\"\"\n",
    "Instructions:\n",
    "\n",
    "It is highly recommended to use a dedicated virtual environment (e.g., venv or conda)\n",
    "to manage project dependencies and avoid conflicts.\n",
    "\n",
    "1. Create a virtual environment (choose one):\n",
    "   - Using venv:\n",
    "     python -m venv .venv\n",
    "     source .venv/bin/activate  # On Linux/macOS\n",
    "     .venv\\Scripts\\activate    # On Windows\n",
    "\n",
    "   - Using conda:\n",
    "     conda create --name fraud_mvp python=3.10  # Or your preferred Python version\n",
    "     conda activate fraud_mvp\n",
    "\n",
    "2. Install required libraries:\n",
    "   Run the following pip command in your activated environment:\n",
    "\n",
    "   pip install pandas numpy scikit-learn matplotlib seaborn jupyterlab <your_chosen_vector_db_client>\n",
    "\n",
    "   Replace <your_chosen_vector_db_client> with the actual client library, e.g.:\n",
    "   - chromadb\n",
    "   - pymilvus\n",
    "   - pinecone-client\n",
    "\n",
    "   Example:\n",
    "   pip install pandas numpy scikit-learn matplotlib seaborn jupyterlab chromadb\n",
    "\n",
    "3. Launch Jupyter Lab:\n",
    "   jupyter lab\n",
    "\n",
    "You can then run this notebook (00) and subsequent notebooks.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Please ensure you have followed the environment setup steps above.\")\n",
    "print(\"Make sure the required libraries (pandas, numpy, etc.) are installed.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Import Libraries\n",
    "# =============================================================================\n",
    "print(\"[2. Importing Libraries]\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import uuid # For generating unique IDs if needed\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Configuration for Data Generation\n",
    "# =============================================================================\n",
    "print(\"[3. Configuration for Data Generation]\")\n",
    "\n",
    "# --- General Settings ---\n",
    "NUM_TAXPAYERS = 5000        # Total number of unique taxpayer profiles to simulate\n",
    "SEED = 42                   # For reproducible random results\n",
    "OUTPUT_DIR = './data'       # Directory to save the generated CSV files\n",
    "\n",
    "# --- Tax Filing Data Settings ---\n",
    "TAX_FILING_RATE = 0.95      # Proportion of taxpayers who file taxes\n",
    "MIN_INCOME = 15000\n",
    "MAX_INCOME = 250000\n",
    "INCOME_LOG_MEAN = np.log(60000) # Center the log-normal distribution around $60k\n",
    "INCOME_LOG_STD = 0.8\n",
    "DEDUCTION_RATE_MEAN = 0.15  # Average deduction rate as a fraction of income\n",
    "DEDUCTION_RATE_STD = 0.05\n",
    "SECTORS = ['Retail', 'Technology', 'Healthcare', 'Finance', 'Construction', 'Services', 'Manufacturing', 'Education', 'Other']\n",
    "SECTOR_PROBS = [0.15, 0.15, 0.12, 0.10, 0.10, 0.18, 0.08, 0.07, 0.05] # Must sum to 1\n",
    "\n",
    "# --- Property Ownership Data Settings ---\n",
    "PROPERTY_OWNERSHIP_RATE = 0.70 # Proportion of taxpayers who own property\n",
    "AVG_PROPERTIES_PER_OWNER = 1.3\n",
    "MIN_PROPERTY_VALUE = 50000\n",
    "MAX_PROPERTY_VALUE = 2000000\n",
    "PROP_VALUE_LOG_MEAN = np.log(250000) # Center around $250k\n",
    "PROP_VALUE_LOG_STD = 0.9\n",
    "LOCATIONS = ['City Center', 'Suburban North', 'Suburban West', 'Rural East', 'Industrial South', 'Coastal Area']\n",
    "LOCATION_PROBS = [0.25, 0.20, 0.20, 0.15, 0.10, 0.10] # Must sum to 1\n",
    "MAX_OWNERSHIP_YEARS_AGO = 20\n",
    "\n",
    "# --- Company Directorship Data Settings (Optional) ---\n",
    "GENERATE_DIRECTORSHIPS = True # Set to False to skip this dataset\n",
    "DIRECTORSHIP_RATE = 0.15    # Proportion of taxpayers who hold directorships\n",
    "NUM_COMPANIES = int(NUM_TAXPAYERS * 0.2) # Number of unique companies\n",
    "AVG_DIRECTORSHIPS_PER_DIRECTOR = 1.1\n",
    "ROLES = ['Director', 'Non-Executive Director', 'Secretary', 'CEO', 'CFO']\n",
    "ROLE_PROBS = [0.50, 0.20, 0.10, 0.10, 0.10] # Must sum to 1\n",
    "\n",
    "# --- Fraud Pattern Settings ---\n",
    "FRAUD_PATTERN_RATIO = 0.03  # Percentage of taxpayers to embed the cross-source pattern in\n",
    "FRAUD_LOW_INCOME_MAX = 20000\n",
    "FRAUD_HIGH_PROP_VALUE_MIN = 800000\n",
    "\n",
    "# --- Noise Settings ---\n",
    "MISSING_VALUE_RATE_TAX = 0.03      # Rate of missing values in tax data (excluding ID)\n",
    "MISSING_VALUE_RATE_PROP = 0.04     # Rate of missing values in property data (excluding ID)\n",
    "MISSING_VALUE_RATE_COMP = 0.02     # Rate of missing values in company data (excluding ID)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration set:\")\n",
    "print(f\"  NUM_TAXPAYERS: {NUM_TAXPAYERS}\")\n",
    "print(f\"  OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"  SEED: {SEED}\")\n",
    "print(f\"  GENERATE_DIRECTORSHIPS: {GENERATE_DIRECTORSHIPS}\")\n",
    "print(f\"  FRAUD_PATTERN_RATIO: {FRAUD_PATTERN_RATIO}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Generate Base Taxpayer IDs\n",
    "# =============================================================================\n",
    "print(\"[4. Generating Base Taxpayer IDs]\")\n",
    "\n",
    "taxpayer_ids = [f\"TXP_{uuid.uuid4().hex[:10].upper()}\" for _ in range(NUM_TAXPAYERS)]\n",
    "print(f\"Generated {len(taxpayer_ids)} unique Taxpayer IDs.\")\n",
    "# print(\"Sample IDs:\", taxpayer_ids[:5])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Generate Synthetic Tax Filings Data\n",
    "# =============================================================================\n",
    "print(\"[5. Generating Synthetic Tax Filings Data]\")\n",
    "\n",
    "# Select subset of taxpayers who file taxes\n",
    "num_filers = int(NUM_TAXPAYERS * TAX_FILING_RATE)\n",
    "filer_ids = np.random.choice(taxpayer_ids, size=num_filers, replace=False)\n",
    "\n",
    "tax_data = []\n",
    "for tax_id in filer_ids:\n",
    "    income = np.random.lognormal(mean=INCOME_LOG_MEAN, sigma=INCOME_LOG_STD)\n",
    "    income = max(MIN_INCOME, min(income, MAX_INCOME)) # Clamp income within bounds\n",
    "\n",
    "    deduction_rate = np.random.normal(loc=DEDUCTION_RATE_MEAN, scale=DEDUCTION_RATE_STD)\n",
    "    deduction_rate = max(0.01, min(deduction_rate, 0.5)) # Clamp deduction rate\n",
    "    deductions = income * deduction_rate\n",
    "    deductions = max(0, deductions) # Ensure non-negative\n",
    "\n",
    "    sector = np.random.choice(SECTORS, p=SECTOR_PROBS)\n",
    "\n",
    "    tax_data.append({\n",
    "        'Taxpayer ID': tax_id,\n",
    "        'Declared Income': round(income, 2),\n",
    "        'Deductions': round(deductions, 2),\n",
    "        'Sector': sector\n",
    "    })\n",
    "\n",
    "tax_df = pd.DataFrame(tax_data)\n",
    "print(f\"Generated initial tax filings data for {len(tax_df)} taxpayers.\")\n",
    "\n",
    "# --- Embed Fraud Pattern (Low Income for specific IDs) ---\n",
    "num_fraud_pattern = int(NUM_TAXPAYERS * FRAUD_PATTERN_RATIO)\n",
    "# Ensure we select from IDs present in the tax filings\n",
    "fraud_candidate_ids = tax_df['Taxpayer ID'].unique()\n",
    "fraud_ids_for_pattern = np.random.choice(fraud_candidate_ids, size=min(num_fraud_pattern, len(fraud_candidate_ids)), replace=False)\n",
    "\n",
    "print(f\"Selected {len(fraud_ids_for_pattern)} Taxpayer IDs to embed cross-source fraud pattern.\")\n",
    "\n",
    "# Override income for these selected IDs\n",
    "fraud_low_incomes = np.random.uniform(MIN_INCOME / 2, FRAUD_LOW_INCOME_MAX, size=len(fraud_ids_for_pattern))\n",
    "tax_df.loc[tax_df['Taxpayer ID'].isin(fraud_ids_for_pattern), 'Declared Income'] = np.round(fraud_low_incomes, 2)\n",
    "# Optionally adjust deductions based on the new low income\n",
    "tax_df.loc[tax_df['Taxpayer ID'].isin(fraud_ids_for_pattern), 'Deductions'] = tax_df['Declared Income'] * np.random.normal(loc=DEDUCTION_RATE_MEAN, scale=DEDUCTION_RATE_STD*0.5) # Lower variation for fraud cases maybe?\n",
    "tax_df['Deductions'] = tax_df['Deductions'].clip(lower=0) # Ensure non-negative deductions\n",
    "\n",
    "print(f\"Modified 'Declared Income' for {len(fraud_ids_for_pattern)} IDs to be below ${FRAUD_LOW_INCOME_MAX:.2f}.\")\n",
    "\n",
    "# --- Add Missing Values ---\n",
    "numeric_cols_tax = ['Declared Income', 'Deductions']\n",
    "categorical_cols_tax = ['Sector']\n",
    "\n",
    "for col in numeric_cols_tax + categorical_cols_tax:\n",
    "    mask = np.random.rand(len(tax_df)) < MISSING_VALUE_RATE_TAX\n",
    "    tax_df.loc[mask, col] = np.nan\n",
    "\n",
    "print(f\"Introduced ~{MISSING_VALUE_RATE_TAX*100:.1f}% missing values into tax data (excluding ID).\")\n",
    "\n",
    "print(\"Sample Tax Filings Data (with potential fraud pattern):\")\n",
    "print(tax_df.head())\n",
    "# Check one fraud ID\n",
    "if len(fraud_ids_for_pattern) > 0:\n",
    "  print(\"\\nExample Tax Record for a 'Fraud Pattern' ID:\")\n",
    "  print(tax_df[tax_df['Taxpayer ID'] == fraud_ids_for_pattern[0]])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Generate Synthetic Property Ownership Data\n",
    "# =============================================================================\n",
    "print(\"[6. Generating Synthetic Property Ownership Data]\")\n",
    "\n",
    "# Select subset of taxpayers who own property\n",
    "num_owners = int(NUM_TAXPAYERS * PROPERTY_OWNERSHIP_RATE)\n",
    "owner_ids_base = np.random.choice(taxpayer_ids, size=num_owners, replace=False)\n",
    "\n",
    "# Ensure the fraud pattern IDs are included among property owners\n",
    "owner_ids_final = np.unique(np.concatenate((owner_ids_base, fraud_ids_for_pattern)))\n",
    "print(f\"Total unique property owners (including fraud pattern IDs): {len(owner_ids_final)}\")\n",
    "\n",
    "property_data = []\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Generate properties, allowing multiple per owner\n",
    "num_properties_total = int(len(owner_ids_final) * AVG_PROPERTIES_PER_OWNER)\n",
    "owner_ids_for_props = np.random.choice(owner_ids_final, size=num_properties_total, replace=True) # Allow multiple properties\n",
    "\n",
    "for owner_id in owner_ids_for_props:\n",
    "    # Determine property value based on whether it's a fraud pattern ID\n",
    "    if owner_id in fraud_ids_for_pattern:\n",
    "        # Assign high property value\n",
    "        prop_value = np.random.uniform(FRAUD_HIGH_PROP_VALUE_MIN, MAX_PROPERTY_VALUE * 1.2) # Allow slightly above max for fraud cases\n",
    "    else:\n",
    "        # Assign \"normal\" property value\n",
    "        prop_value = np.random.lognormal(mean=PROP_VALUE_LOG_MEAN, sigma=PROP_VALUE_LOG_STD)\n",
    "        prop_value = max(MIN_PROPERTY_VALUE, min(prop_value, MAX_PROPERTY_VALUE)) # Clamp\n",
    "\n",
    "    location = np.random.choice(LOCATIONS, p=LOCATION_PROBS)\n",
    "\n",
    "    # Generate ownership date within the last N years\n",
    "    days_ago = random.randint(1, MAX_OWNERSHIP_YEARS_AGO * 365)\n",
    "    ownership_date = current_date - timedelta(days=days_ago)\n",
    "\n",
    "    property_data.append({\n",
    "        'Taxpayer ID': owner_id,\n",
    "        'Property Value': round(prop_value, 2),\n",
    "        'Location': location,\n",
    "        'Ownership Date': ownership_date.strftime('%Y-%m-%d') # Format as string YYYY-MM-DD\n",
    "    })\n",
    "\n",
    "property_df = pd.DataFrame(property_data)\n",
    "print(f\"Generated {len(property_df)} property records for {property_df['Taxpayer ID'].nunique()} unique owners.\")\n",
    "\n",
    "\n",
    "# --- Add Missing Values ---\n",
    "numeric_cols_prop = ['Property Value']\n",
    "categorical_cols_prop = ['Location']\n",
    "date_cols_prop = ['Ownership Date'] # Even though it's string, treat conceptually as date\n",
    "\n",
    "for col in numeric_cols_prop + categorical_cols_prop + date_cols_prop:\n",
    "    mask = np.random.rand(len(property_df)) < MISSING_VALUE_RATE_PROP\n",
    "    property_df.loc[mask, col] = np.nan\n",
    "\n",
    "print(f\"Introduced ~{MISSING_VALUE_RATE_PROP*100:.1f}% missing values into property data (excluding ID).\")\n",
    "\n",
    "print(\"\\nSample Property Ownership Data:\")\n",
    "print(property_df.head())\n",
    "# Check one fraud ID\n",
    "if len(fraud_ids_for_pattern) > 0:\n",
    "    print(\"\\nExample Property Record(s) for the same 'Fraud Pattern' ID:\")\n",
    "    print(property_df[property_df['Taxpayer ID'] == fraud_ids_for_pattern[0]])\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Generate Synthetic Company Directorships Data (Optional)\n",
    "# =============================================================================\n",
    "print(\"[7. Generating Synthetic Company Directorships Data (Optional)]\")\n",
    "\n",
    "if GENERATE_DIRECTORSHIPS:\n",
    "    # Generate unique Company IDs\n",
    "    company_ids = [f\"COMP_{uuid.uuid4().hex[:8].upper()}\" for _ in range(NUM_COMPANIES)]\n",
    "\n",
    "    # Select subset of taxpayers who are directors\n",
    "    num_directors = int(NUM_TAXPAYERS * DIRECTORSHIP_RATE)\n",
    "    director_ids_base = np.random.choice(taxpayer_ids, size=num_directors, replace=False)\n",
    "\n",
    "    # Optionally, ensure some fraud pattern IDs are directors (or make them less likely?)\n",
    "    # For this example, we keep it random relative to the base population.\n",
    "    # director_ids_final = np.unique(np.concatenate((director_ids_base, subset_of_fraud_ids)))\n",
    "    director_ids_final = director_ids_base\n",
    "    print(f\"Selected {len(director_ids_final)} unique taxpayers as potential directors.\")\n",
    "\n",
    "\n",
    "    company_data = []\n",
    "    num_directorships_total = int(len(director_ids_final) * AVG_DIRECTORSHIPS_PER_DIRECTOR)\n",
    "    director_ids_for_roles = np.random.choice(director_ids_final, size=num_directorships_total, replace=True) # Allow multiple roles\n",
    "\n",
    "    for director_id in director_ids_for_roles:\n",
    "        company_id = random.choice(company_ids)\n",
    "        role = np.random.choice(ROLES, p=ROLE_PROBS)\n",
    "\n",
    "        company_data.append({\n",
    "            'Taxpayer ID': director_id,\n",
    "            'Company ID': company_id,\n",
    "            'Director Role': role\n",
    "        })\n",
    "\n",
    "    company_df = pd.DataFrame(company_data)\n",
    "    # Remove exact duplicates (same person, same company, same role)\n",
    "    company_df = company_df.drop_duplicates()\n",
    "    print(f\"Generated {len(company_df)} directorship records for {company_df['Taxpayer ID'].nunique()} unique directors across {company_df['Company ID'].nunique()} companies.\")\n",
    "\n",
    "    # --- Add Missing Values ---\n",
    "    categorical_cols_comp = ['Director Role'] # Company ID assumed mandatory\n",
    "\n",
    "    for col in categorical_cols_comp:\n",
    "      mask = np.random.rand(len(company_df)) < MISSING_VALUE_RATE_COMP\n",
    "      company_df.loc[mask, col] = np.nan\n",
    "\n",
    "    print(f\"Introduced ~{MISSING_VALUE_RATE_COMP*100:.1f}% missing values into company data (excluding ID).\")\n",
    "\n",
    "    print(\"\\nSample Company Directorship Data:\")\n",
    "    print(company_df.head())\n",
    "    # Check one fraud ID if they happen to be a director\n",
    "    if len(fraud_ids_for_pattern) > 0:\n",
    "        print(\"\\nExample Directorship Record(s) for the same 'Fraud Pattern' ID (if they exist):\")\n",
    "        print(company_df[company_df['Taxpayer ID'] == fraud_ids_for_pattern[0]])\n",
    "\n",
    "else:\n",
    "    print(\"Skipping generation of Company Directorships data as GENERATE_DIRECTORSHIPS is False.\")\n",
    "    company_df = None\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Save Generated Data to CSV\n",
    "# =============================================================================\n",
    "print(\"[8. Saving Generated Data to CSV]\")\n",
    "\n",
    "try:\n",
    "    tax_file_path = os.path.join(OUTPUT_DIR, 'synthetic_tax_filings.csv')\n",
    "    tax_df.to_csv(tax_file_path, index=False)\n",
    "    print(f\"Successfully saved tax data to: {tax_file_path}\")\n",
    "\n",
    "    property_file_path = os.path.join(OUTPUT_DIR, 'synthetic_property_ownership.csv')\n",
    "    property_df.to_csv(property_file_path, index=False)\n",
    "    print(f\"Successfully saved property data to: {property_file_path}\")\n",
    "\n",
    "    if company_df is not None:\n",
    "        company_file_path = os.path.join(OUTPUT_DIR, 'synthetic_company_directorships.csv')\n",
    "        company_df.to_csv(company_file_path, index=False)\n",
    "        print(f\"Successfully saved company directorship data to: {company_file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR saving data files: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Verification Step (Optional)\n",
    "# =============================================================================\n",
    "print(\"[9. Verification Step (Optional)]\")\n",
    "\n",
    "print(\"Quick check of generated files:\")\n",
    "try:\n",
    "    print(f\"\\nTax File ({tax_file_path}):\")\n",
    "    df_check = pd.read_csv(tax_file_path)\n",
    "    print(df_check.info())\n",
    "    print(df_check.head())\n",
    "\n",
    "    print(f\"\\nProperty File ({property_file_path}):\")\n",
    "    df_check = pd.read_csv(property_file_path)\n",
    "    print(df_check.info())\n",
    "    print(df_check.head())\n",
    "\n",
    "    if company_df is not None:\n",
    "        print(f\"\\nCompany File ({company_file_path}):\")\n",
    "        df_check = pd.read_csv(company_file_path)\n",
    "        print(df_check.info())\n",
    "        print(df_check.head())\n",
    "\n",
    "    # Verify a known fraud pattern ID\n",
    "    if len(fraud_ids_for_pattern) > 0:\n",
    "        verify_id = fraud_ids_for_pattern[0]\n",
    "        print(f\"\\nVerifying cross-source pattern for ID: {verify_id}\")\n",
    "        tax_record = pd.read_csv(tax_file_path)\n",
    "        tax_record = tax_record[tax_record['Taxpayer ID'] == verify_id]\n",
    "        print(\"Tax Record:\")\n",
    "        print(tax_record[['Taxpayer ID', 'Declared Income']])\n",
    "\n",
    "        prop_record = pd.read_csv(property_file_path)\n",
    "        prop_record = prop_record[prop_record['Taxpayer ID'] == verify_id]\n",
    "        print(\"\\nProperty Record(s):\")\n",
    "        print(prop_record[['Taxpayer ID', 'Property Value']])\n",
    "        # Check if the expected pattern holds (low income, high property value)\n",
    "        is_low_income = tax_record['Declared Income'].iloc[0] <= FRAUD_LOW_INCOME_MAX if not tax_record.empty else False\n",
    "        has_high_prop = prop_record['Property Value'].max() >= FRAUD_HIGH_PROP_VALUE_MIN if not prop_record.empty else False\n",
    "        print(f\"\\nPattern Check -> Low Income: {is_low_income}, High Property Value: {has_high_prop}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during verification read: {e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. Conclusion\n",
    "# =============================================================================\n",
    "print(\"[10. Conclusion]\")\n",
    "print(\"Notebook 00 finished.\")\n",
    "print(\"Environment setup guidance provided.\")\n",
    "print(\"Synthetic data files generated and saved:\")\n",
    "print(f\"  - {os.path.join(OUTPUT_DIR, 'synthetic_tax_filings.csv')}\")\n",
    "print(f\"  - {os.path.join(OUTPUT_DIR, 'synthetic_property_ownership.csv')}\")\n",
    "if company_df is not None:\n",
    "    print(f\"  - {os.path.join(OUTPUT_DIR, 'synthetic_company_directorships.csv')}\")\n",
    "print(\"Data includes embedded cross-source patterns for selected 'fraudulent' profiles.\")\n",
    "print(\"\\nReady to proceed to Notebook 01: Source Data Exploration & Initial Cleaning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a460d1-bc5f-4bab-a715-4587328a4990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
