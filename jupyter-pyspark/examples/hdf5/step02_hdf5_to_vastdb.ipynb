{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82af41c3-21f5-4fbb-9fd5-fbdf863d72f5",
   "metadata": {},
   "source": [
    "# Import HDF5 file into Vast DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c8af4-ea3a-440f-a9c1-637a37d84c0c",
   "metadata": {},
   "source": [
    "## Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831789ea-2d52-42b2-bd48-f177600b543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = \"https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06384bb-d822-4616-83b9-1588f911d330",
   "metadata": {},
   "source": [
    "## Vast DB destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec46c0e-94db-43ae-81d5-89b48c8e37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "VASTDB_ENDPOINT = os.getenv(\"VASTDB_ENDPOINT\")\n",
    "VASTDB_ACCESS_KEY = os.getenv(\"VASTDB_ACCESS_KEY\")\n",
    "VASTDB_SECRET_KEY = os.getenv(\"VASTDB_SECRET_KEY\")\n",
    "\n",
    "# Use NYT BUCKET (DB) for now\n",
    "VASTDB_NYT_BUCKET=os.getenv(\"VASTDB_NYT_BUCKET\")\n",
    "schema_name = 'cosmology'\n",
    "table_name = 'particles'\n",
    "\n",
    "url = \"https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d222eb0-c5bd-4663-b191-20b71bf9f3db",
   "metadata": {},
   "source": [
    "## Vast DB utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58724d54-203e-4dce-abd8-54ba66b99cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://vast-data.github.io/data-platform-field-docs/vast_database/ingestion/python_sdk_parquet_import.html\n",
    "\n",
    "import io\n",
    "import os\n",
    "import pyarrow as pa\n",
    "from pyarrow import csv as pa_csv\n",
    "import pyarrow.parquet as pq\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vastdb\n",
    "from vastdb.config import QueryConfig\n",
    "\n",
    "def read_parquet(file_path):\n",
    "    \"\"\"Reads Parquet data from a file.\"\"\"\n",
    "    try:\n",
    "        return pq.read_table(file_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading Parquet file: {e}\") from e\n",
    "\n",
    "def connect_to_vastdb(endpoint, access_key, secret_key):\n",
    "    \"\"\"Connects to VastDB.\"\"\"\n",
    "    try:\n",
    "        session = vastdb.connect(endpoint=endpoint, access=access_key, secret=secret_key)\n",
    "        print(\"Connected to VastDB\")\n",
    "        return session\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to connect to VastDB: {e}\") from e\n",
    "\n",
    "def write_to_vastdb(session, bucket_name, schema_name, table_name, pa_table):\n",
    "    \"\"\"Writes data to VastDB.\"\"\"\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "\n",
    "        table = schema.table(table_name, fail_if_missing=False) or schema.create_table(table_name, pa_table.schema)\n",
    "\n",
    "        columns_to_add = get_columns_to_add(table.arrow_schema, pa_table.schema)\n",
    "        for column in columns_to_add:\n",
    "            table.add_column(column)\n",
    "\n",
    "        table.insert(pa_table)\n",
    "\n",
    "def get_columns_to_add(existing_schema, desired_schema):\n",
    "    \"\"\"Identifies columns to add to an existing schema.\"\"\"\n",
    "    existing_fields = set(existing_schema.names)\n",
    "    desired_fields = set(desired_schema.names)\n",
    "    return [pa.schema([pa.field(name, desired_schema.field(name).type)]) for name in desired_fields - existing_fields]\n",
    "\n",
    "\n",
    "def query_vastdb(session, bucket_name, schema_name, table_name, limit=None):\n",
    "    \"\"\"Writes data to VastDB.\"\"\"\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "        table = schema.table(table_name, fail_if_missing=False) or schema.create_table(table_name, pa_table.schema)\n",
    "\n",
    "        if limit:\n",
    "            # See: https://vast-data.github.io/data-platform-field-docs/vast_database/sdk_ref/limit_n.html\n",
    "            config = QueryConfig(\n",
    "                num_splits=1,                \t  # Manually specify 1 split\n",
    "                num_sub_splits=1,                 # Each split will be divided into 1 subsplits\n",
    "                limit_rows_per_sub_split=limit,   # Each subsplit will process 10 rows at a time\n",
    "            )\n",
    "            batches = table.select(config=config)\n",
    "            first_batch = next(batches)\n",
    "            return first_batch.to_pandas()\n",
    "        else:\n",
    "            return table.select().read_all().to_pandas()\n",
    "\n",
    "def drop_vastdb_table(session, bucket_name, schema_name, table_name):\n",
    "    \"\"\"Writes data to VastDB.\"\"\"\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "\n",
    "        table = schema.table(table_name, fail_if_missing=False)\n",
    "        if table:\n",
    "            table.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5ed67c-89fa-444c-987c-e50a745212d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to VastDB\n"
     ]
    }
   ],
   "source": [
    "session = connect_to_vastdb(VASTDB_ENDPOINT, VASTDB_ACCESS_KEY, VASTDB_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df301383-9904-4752-9e8c-7086d194f22e",
   "metadata": {},
   "source": [
    "## List files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77dbd6ff-a39c-4cfa-911e-2fd983761ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_file_list(source_url):\n",
    "    # Send a GET request to fetch the HTML content of the directory\n",
    "    response = requests.get(source_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all <a> tags (which typically contain links)\n",
    "        files = []\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            if href and href.endswith('.hdf5'):\n",
    "                files.append(f\"{source_url}/{href}\")\n",
    "        \n",
    "        return files\n",
    "    else:\n",
    "        print(f\"Failed to access {url}. HTTP Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f3f799-9f41-4631-a94e-f37c61742ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000//snap_028_z000p000.1.hdf5',\n",
       " 'https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000//snap_028_z000p000.2.hdf5',\n",
       " 'https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000//snap_028_z000p000.3.hdf5',\n",
       " 'https://virgodb.cosma.dur.ac.uk/public/agb/snapshot_028_z000p000//snap_028_z000p000.4.hdf5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first few urls\n",
    "get_file_list(SOURCE_URL)[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e9d1f-08e1-4314-9b72-93b8a1133a23",
   "metadata": {},
   "source": [
    "## Download and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f8dbf0-c484-4f7f-b413-a1ec7349c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we don't have old data in the table\n",
    "drop_vastdb_table(session, VASTDB_NYT_BUCKET, schema_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7aac5a0-c666-4c12-baf0-a276884b997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_file(file_url, save_dir):\n",
    "    \"\"\"\n",
    "    Downloads a file from the given URL and saves it to the specified directory with a progress bar.\n",
    "    \n",
    "    Args:\n",
    "        file_url (str): URL of the file to download.\n",
    "        save_dir (str): Directory where the file will be saved.\n",
    "    \n",
    "    Returns:\n",
    "        str: Local path to the downloaded file.\n",
    "    \"\"\"\n",
    "    filename = file_url.split('/')[-1]\n",
    "    local_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    response = requests.get(file_url, stream=True)\n",
    "    response.raise_for_status()  # Raise HTTP errors, if any\n",
    "\n",
    "    total_size = int(response.headers.get('content-length', 0))  # Total file size in bytes\n",
    "    chunk_size = 8192  # Read in chunks of 8 KB\n",
    "\n",
    "    with open(local_path, 'wb') as f, tqdm(\n",
    "        desc=f\"Downloading {filename}\",\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        mininterval=0.5,\n",
    "    ) as progress:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            f.write(chunk)\n",
    "            progress.update(len(chunk))\n",
    "\n",
    "    return local_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714dd6e8-a6a5-4eef-ad88-b4fd11e8110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def import_table_particles(hdf5_file_path):\n",
    "\n",
    "    with h5py.File(hdf5_file_path, 'r') as f:\n",
    "        # Get dataset sizes\n",
    "        coordinates_dataset = f['PartType0/Coordinates']\n",
    "        velocities_dataset = f['PartType0/Velocity']\n",
    "        mass_dataset = f['PartType0/Mass']\n",
    "    \n",
    "        chunk_size = 10000  # Number of rows to process at a time\n",
    "        total_rows = coordinates_dataset.shape[0]\n",
    "    \n",
    "        # Create a progress bar using tqdm\n",
    "        progress_bar = tqdm(total=total_rows, \n",
    "                            unit=\"rows\", \n",
    "                            desc=\"Importing 'Particles' to Vast DB\",\n",
    "                            mininterval=0.5)\n",
    "    \n",
    "        for start in range(0, total_rows, chunk_size):\n",
    "            end = min(start + chunk_size, total_rows)\n",
    "    \n",
    "            # Load a chunk of data\n",
    "            coordinates_chunk = coordinates_dataset[start:end]\n",
    "            velocities_chunk = velocities_dataset[start:end]\n",
    "            mass_chunk = mass_dataset[start:end]\n",
    "    \n",
    "            # Convert to Arrow Table\n",
    "            table = pa.Table.from_pandas(pd.DataFrame({\n",
    "                'Coordinates': list(coordinates_chunk),\n",
    "                'Velocity': list(velocities_chunk),\n",
    "                'Mass': mass_chunk\n",
    "            }))\n",
    "    \n",
    "            write_to_vastdb(session, VASTDB_NYT_BUCKET, schema_name, table_name, table)\n",
    "            progress_bar.update(chunk_size)\n",
    "            \n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da67fd9-5b46-43c9-97a2-83e00430405d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c3096ab25f436ab06d3ced5d567c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading snap_028_z000p000.0.hdf5:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b433282b7b37466a9d872b7d21c8e1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing 'Particles' to Vast DB:   0%|          | 0/12643607 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0b3b4ecdb142168febaa6c07923aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading snap_028_z000p000.1.hdf5:   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070a2e950aba41a0825713cf018bf84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing 'Particles' to Vast DB:   0%|          | 0/12597522 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365bc4ce5d14a938e080fe60c1435a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading snap_028_z000p000.2.hdf5:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Temporary directory to save downloaded files\n",
    "temp_dir = \"temp_files\"\n",
    "\n",
    "if os.path.exists(temp_dir):\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=False)\n",
    "\n",
    "for file_url in get_file_list(SOURCE_URL):\n",
    "    local_path = download_file(file_url, temp_dir)    \n",
    "    import_table_particles(local_path)\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        os.remove(local_path)\n",
    "\n",
    "# Cleanup temporary directory\n",
    "os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06840d73-e0dc-4828-ae3a-e5995ddb1329",
   "metadata": {},
   "source": [
    "## Verify data in Vast DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e76112-4c68-4d41-83c1-84b572012142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = query_vastdb(session, VASTDB_NYT_BUCKET, schema_name, table_name, limit=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f884b41-4117-425a-8774-3ffb3ec81d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
