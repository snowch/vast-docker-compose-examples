{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10fed33d-be68-4c1b-a045-30f853f1e6a5",
   "metadata": {},
   "source": [
    "# Import Yellow Taxi Data - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb93c071-3c28-4c32-b782-2512f38eec58",
   "metadata": {},
   "source": [
    "Import yellow taxi data into Vast S3 and Vast DB.\n",
    "\n",
    "The schema changes over time, so we need to evolve the schema:\n",
    "- currently only new fields are added during loading\n",
    "- datatype changes are handled before loading the parquet into VastDB\n",
    "- column renames are handled before loading the parquet into VastDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb0d111-afe5-4d0b-a5f0-a6fa1a8967d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --quiet vastdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31dab003-4d9f-47b0-8181-63797260867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "from pyarrow import csv as pa_csv\n",
    "import requests\n",
    "\n",
    "# Custom imports for VASTDB\n",
    "import vastdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ed0c37-64da-4137-abfa-cdeb705dd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VASTDB_ENDPOINT = os.getenv(\"VASTDB_ENDPOINT\")\n",
    "VASTDB_ACCESS_KEY = os.getenv(\"VASTDB_ACCESS_KEY\")\n",
    "VASTDB_SECRET_KEY = os.getenv(\"VASTDB_SECRET_KEY\")\n",
    "\n",
    "VASTDB_TWITTER_INGEST_BUCKET = os.getenv(\"VASTDB_TWITTER_INGEST_BUCKET\")\n",
    "VASTDB_TWITTER_INGEST_SCHEMA = os.getenv(\"VASTDB_TWITTER_INGEST_SCHEMA\")\n",
    "\n",
    "S3_ENDPOINT = os.getenv(\"S3A_ENDPOINT\")\n",
    "S3_ACCESS_KEY = os.getenv(\"S3A_ACCESS_KEY\")\n",
    "S3_SECRET_KEY = os.getenv(\"S3A_SECRET_KEY\")\n",
    "S3_BUCKET = os.getenv(\"S3A_BUCKET\")\n",
    "\n",
    "###### SET THIS ######\n",
    "VASTDB_TWITTER_INGEST_TABLE = 'yellow_trip_data'\n",
    "###### SET THIS ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40282e3-33b5-4443-a757-adb9c627a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "VASTDB_ENDPOINT=http://172.200.204.2:80\n",
      "VASTDB_ACCESS_KEY=QXN5\n",
      "VASTDB_SECRET_KEY=****oLGr\n",
      "VASTDB_TWITTER_INGEST_BUCKET=csnow-db\n",
      "VASTDB_TWITTER_INGEST_SCHEMA=social_media\n",
      "VASTDB_TWITTER_INGEST_TABLE=yellow_trip_data\n",
      "---\n",
      "S3_ENDPOINT=http://172.200.204.2:80\n",
      "S3_ACCESS_KEY=QXN5\n",
      "S3_SECRET_KEY=****oLGr\n",
      "S3_BUCKET=csnow-bucket\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "---\n",
    "VASTDB_ENDPOINT={VASTDB_ENDPOINT}\n",
    "VASTDB_ACCESS_KEY={VASTDB_ACCESS_KEY[-4:]}\n",
    "VASTDB_SECRET_KEY=****{VASTDB_SECRET_KEY[-4:]}\n",
    "VASTDB_TWITTER_INGEST_BUCKET={VASTDB_TWITTER_INGEST_BUCKET}\n",
    "VASTDB_TWITTER_INGEST_SCHEMA={VASTDB_TWITTER_INGEST_SCHEMA}\n",
    "VASTDB_TWITTER_INGEST_TABLE={VASTDB_TWITTER_INGEST_TABLE}\n",
    "---\n",
    "S3_ENDPOINT={S3_ENDPOINT}\n",
    "S3_ACCESS_KEY={S3_ACCESS_KEY[-4:]}\n",
    "S3_SECRET_KEY=****{VASTDB_SECRET_KEY[-4:]}\n",
    "S3_BUCKET={S3_BUCKET}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954ed1e1-b4ae-4522-b6b8-5bd1e5f67283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(file_path):\n",
    "    \"\"\"Reads Parquet data from a file.\"\"\"\n",
    "    try:\n",
    "        return pq.read_table(file_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading Parquet file: {e}\") from e\n",
    "\n",
    "def connect_to_vastdb(endpoint, access_key, secret_key):\n",
    "    \"\"\"Connects to VastDB.\"\"\"\n",
    "    try:\n",
    "        session = vastdb.connect(endpoint=endpoint, access=access_key, secret=secret_key)\n",
    "        print(\"Connected to VastDB\")\n",
    "        return session\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to connect to VastDB: {e}\") from e\n",
    "\n",
    "def write_to_vastdb(session, bucket_name, schema_name, table_name, pa_table):\n",
    "    \"\"\"Writes data to VastDB.\"\"\"\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "\n",
    "        table = schema.table(table_name, fail_if_missing=False) or schema.create_table(table_name, pa_table.schema)\n",
    "\n",
    "        columns_to_add = get_columns_to_add(table.arrow_schema, pa_table.schema)\n",
    "        for column in columns_to_add:\n",
    "            table.add_column(column)\n",
    "            \n",
    "        try:\n",
    "            # Attempt to insert data\n",
    "            table.insert(pa_table)\n",
    "            print(f\"Inserted parquet into {table.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during table.insert: {e}\")\n",
    "            \n",
    "            # Perform schema diff if insert fails\n",
    "            perform_schema_diff(table.arrow_schema, pa_table.schema)\n",
    "            raise  # Re-raise the exception for further handling\n",
    "\n",
    "def perform_schema_diff(existing_schema, new_schema):\n",
    "    \"\"\"Compares two schemas and logs the differences, clarifying which is existing and which is new.\"\"\"\n",
    "    existing_fields = {field.name.lower(): field for field in existing_schema}\n",
    "    new_fields = {field.name.lower(): field for field in new_schema}\n",
    "\n",
    "    print(\"\\nSchema Differences:\")\n",
    "    \n",
    "    # Check for missing fields in the existing schema\n",
    "    missing_in_existing = [field for name, field in new_fields.items() if name not in existing_fields]\n",
    "    if missing_in_existing:\n",
    "        print(\"Fields missing in the existing schema:\")\n",
    "        for field in missing_in_existing:\n",
    "            print(f\"  - {field.name} (new): {field.type}\")\n",
    "    else:\n",
    "        print(\"No fields are missing in the existing schema.\")\n",
    "    \n",
    "    # Check for extra fields in the existing schema\n",
    "    extra_in_existing = [field for name, field in existing_fields.items() if name not in new_fields]\n",
    "    if extra_in_existing:\n",
    "        print(\"Fields present in the existing schema but not in the new schema:\")\n",
    "        for field in extra_in_existing:\n",
    "            print(f\"  - {field.name} (existing): {field.type}\")\n",
    "    else:\n",
    "        print(\"No extra fields in the existing schema.\")\n",
    "    \n",
    "    # Check for type mismatches\n",
    "    type_mismatches = [\n",
    "        (existing_fields[name].name, existing_fields[name].type, new_fields[name].type)\n",
    "        for name in new_fields\n",
    "        if name in existing_fields and existing_fields[name].type != new_fields[name].type\n",
    "    ]\n",
    "    if type_mismatches:\n",
    "        print(\"Type mismatches:\")\n",
    "        for name, existing_type, new_type in type_mismatches:\n",
    "            print(f\"  - {name}: (existing) {existing_type} -> (new) {new_type}\")\n",
    "    else:\n",
    "        print(\"No type mismatches found.\")\n",
    "\n",
    "def import_to_vastdb(session, bucket_name, schema_name, table_name, files_to_import):\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "        table = schema.table(table_name, fail_if_missing=False)\n",
    "\n",
    "        if table:\n",
    "            table.import_files(files_to_import=files_to_import)\n",
    "        else:\n",
    "            table = vastdb.util.create_table_from_files(\n",
    "                schema=schema, \n",
    "                table_name=table_name,\n",
    "                parquet_files=files_to_import\n",
    "            )\n",
    "\n",
    "def get_columns_to_add(existing_schema, desired_schema):\n",
    "    \"\"\"Identifies columns to add to an existing schema.\"\"\"\n",
    "    existing_fields = set(existing_schema.names)\n",
    "    desired_fields = set(desired_schema.names)\n",
    "    return [pa.schema([pa.field(name, desired_schema.field(name).type)]) for name in desired_fields - existing_fields]\n",
    "\n",
    "\n",
    "def query_vastdb(session, bucket_name, schema_name, table_name):\n",
    "    \"\"\"Writes data to VastDB.\"\"\"\n",
    "    with session.transaction() as tx:\n",
    "        bucket = tx.bucket(bucket_name)\n",
    "        schema = bucket.schema(schema_name, fail_if_missing=False) or bucket.create_schema(schema_name)\n",
    "        table = schema.table(table_name, fail_if_missing=False) or schema.create_table(table_name, pa_table.schema)\n",
    "\n",
    "        return table.select().read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f14638-9819-4632-a87e-8a7ba5a9b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to download files\n",
    "def download_file(url):\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    \n",
    "    # Check if file exists, skip if so\n",
    "    if not os.path.exists(file_name):\n",
    "        # print(f\"Downloading {file_name}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Downloaded {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {file_name}. Status code: {response.status_code}\")\n",
    "    else:\n",
    "        print(f\"{file_name} already exists. Skipping download.\")\n",
    "\n",
    "\n",
    "# Define a function to upload the file to S3\n",
    "def upload_to_s3(s3_client, file_path, bucket_name, s3_key):\n",
    "    try:\n",
    "        # print(f\"Uploading {file_path} to S3 bucket {bucket_name}...\")\n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"File uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {file_path} was not found.\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "def file_exists_in_s3(s3_client, bucket_name, s3_key):\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "        return True  # File exists\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            return False  # File does not exist\n",
    "        raise  # Re-raise other exceptions\n",
    "\n",
    "\n",
    "# Define a function to delete the file after processing\n",
    "def delete_local_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115a619b-9ae3-45a9-83e6-a6f2d9748f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "def process_parquet(file_path):\n",
    "    \"\"\"Process and transform the Parquet file data.\"\"\"\n",
    "    # Load the Parquet file\n",
    "    pa_table = pq.read_table(file_path)\n",
    "    \n",
    "    # Convert TIMESTAMP[US] to a standard timestamp (nanoseconds)\n",
    "    columns_to_convert = ['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "    for column in columns_to_convert:\n",
    "        if column in pa_table.column_names:\n",
    "            # Convert the column to a timestamp with nanosecond precision\n",
    "            pa_table = pa_table.set_column(\n",
    "                pa_table.column_names.index(column),\n",
    "                column,\n",
    "                pc.cast(pa_table[column], pa.timestamp('ns'))\n",
    "            )\n",
    "    \n",
    "    # Handle NULL columns (e.g., 'airport_fee') and rename to 'Airport_fee'\n",
    "    null_column = 'airport_fee'\n",
    "    renamed_column = 'Airport_fee'\n",
    "    if null_column in pa_table.column_names:\n",
    "        # Replace NULL values with 0.0 and rename the column\n",
    "        pa_table = pa_table.set_column(\n",
    "            pa_table.column_names.index(null_column),\n",
    "            renamed_column,\n",
    "            pc.if_else(pc.is_null(pa_table[null_column]), pa.scalar(0.0, pa.float64()), pa_table[null_column])\n",
    "        )\n",
    "    \n",
    "    # Handle casting of passenger_count to int64\n",
    "    passenger_count_column = 'passenger_count'\n",
    "    if passenger_count_column in pa_table.column_names:\n",
    "        # Cast 'passenger_count' to int64\n",
    "        pa_table = pa_table.set_column(\n",
    "            pa_table.column_names.index(passenger_count_column),\n",
    "            passenger_count_column,\n",
    "            pc.cast(pa_table[passenger_count_column], pa.int64())\n",
    "        )\n",
    "    \n",
    "    # Handle casting of RatecodeID to int32\n",
    "    ratecode_column = 'RatecodeID'\n",
    "    if ratecode_column in pa_table.column_names:\n",
    "        # Cast 'RatecodeID' to int32\n",
    "        pa_table = pa_table.set_column(\n",
    "            pa_table.column_names.index(ratecode_column),\n",
    "            ratecode_column,\n",
    "            pc.cast(pa_table[ratecode_column], pa.int32())\n",
    "        )\n",
    "    \n",
    "    # Handle LARGE_STRING columns (e.g., 'store_and_fwd_flag')\n",
    "    string_columns_to_cast = ['store_and_fwd_flag']\n",
    "    for column in string_columns_to_cast:\n",
    "        if column in pa_table.column_names:\n",
    "            # Convert the column to a STRING type\n",
    "            pa_table = pa_table.set_column(\n",
    "                pa_table.column_names.index(column),\n",
    "                column,\n",
    "                pc.cast(pa_table[column], pa.string())\n",
    "            )\n",
    "            \n",
    "    # Write the processed table back to disk as a Parquet file\n",
    "    pq.write_table(pa_table, file_path)\n",
    "    print(f\"Processed file written to {file_path}\")\n",
    "    \n",
    "    # Return the processed table\n",
    "    return pa_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857881a5-400d-402c-aad7-bdef40751337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "# Save a reference to the original print function\n",
    "original_print = builtins.print\n",
    "\n",
    "def indented_print(*args, **kwargs):\n",
    "    \"\"\"Custom print function with a two-space indent.\"\"\"\n",
    "    original_print(\"  \", *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d960a6e-c4ea-45c0-a0ae-04e5a58cd439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to VastDB\n"
     ]
    }
   ],
   "source": [
    "session = connect_to_vastdb(VASTDB_ENDPOINT, VASTDB_ACCESS_KEY, VASTDB_SECRET_KEY)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client(\n",
    "    's3', \n",
    "    region_name='vast',\n",
    "    endpoint_url=S3_ENDPOINT,\n",
    "    aws_access_key_id=S3_ACCESS_KEY,\n",
    "    aws_secret_access_key=S3_SECRET_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fb66cf8-0074-454f-980b-f757bc44954c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2019 01\n",
      "   Downloaded yellow_tripdata_2019-01.parquet\n",
      "   Processed file written to yellow_tripdata_2019-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-01.parquet\n",
      "Processing 2019 02\n",
      "   yellow_tripdata_2019-02.parquet already exists. Skipping download.\n",
      "   Processed file written to yellow_tripdata_2019-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-02.parquet\n",
      "Processing 2019 03\n",
      "   yellow_tripdata_2019-03.parquet already exists. Skipping download.\n",
      "   Processed file written to yellow_tripdata_2019-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-03.parquet\n",
      "Processing 2019 04\n",
      "   Downloaded yellow_tripdata_2019-04.parquet\n",
      "   Processed file written to yellow_tripdata_2019-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-04.parquet\n",
      "Processing 2019 05\n",
      "   Downloaded yellow_tripdata_2019-05.parquet\n",
      "   Processed file written to yellow_tripdata_2019-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-05.parquet\n",
      "Processing 2019 06\n",
      "   Downloaded yellow_tripdata_2019-06.parquet\n",
      "   Processed file written to yellow_tripdata_2019-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-06.parquet\n",
      "Processing 2019 07\n",
      "   Downloaded yellow_tripdata_2019-07.parquet\n",
      "   Processed file written to yellow_tripdata_2019-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-07.parquet\n",
      "Processing 2019 08\n",
      "   Downloaded yellow_tripdata_2019-08.parquet\n",
      "   Processed file written to yellow_tripdata_2019-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-08.parquet\n",
      "Processing 2019 09\n",
      "   Downloaded yellow_tripdata_2019-09.parquet\n",
      "   Processed file written to yellow_tripdata_2019-09.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-09.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-09.parquet\n",
      "Processing 2019 10\n",
      "   Downloaded yellow_tripdata_2019-10.parquet\n",
      "   Processed file written to yellow_tripdata_2019-10.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-10.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-10.parquet\n",
      "Processing 2019 11\n",
      "   Downloaded yellow_tripdata_2019-11.parquet\n",
      "   Processed file written to yellow_tripdata_2019-11.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-11.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-11.parquet\n",
      "Processing 2019 12\n",
      "   Downloaded yellow_tripdata_2019-12.parquet\n",
      "   Processed file written to yellow_tripdata_2019-12.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2019-12.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2019-12.parquet\n",
      "Processing 2020 01\n",
      "   Downloaded yellow_tripdata_2020-01.parquet\n",
      "   Processed file written to yellow_tripdata_2020-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-01.parquet\n",
      "Processing 2020 02\n",
      "   Downloaded yellow_tripdata_2020-02.parquet\n",
      "   Processed file written to yellow_tripdata_2020-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-02.parquet\n",
      "Processing 2020 03\n",
      "   Downloaded yellow_tripdata_2020-03.parquet\n",
      "   Processed file written to yellow_tripdata_2020-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-03.parquet\n",
      "Processing 2020 04\n",
      "   Downloaded yellow_tripdata_2020-04.parquet\n",
      "   Processed file written to yellow_tripdata_2020-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-04.parquet\n",
      "Processing 2020 05\n",
      "   Downloaded yellow_tripdata_2020-05.parquet\n",
      "   Processed file written to yellow_tripdata_2020-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-05.parquet\n",
      "Processing 2020 06\n",
      "   Downloaded yellow_tripdata_2020-06.parquet\n",
      "   Processed file written to yellow_tripdata_2020-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-06.parquet\n",
      "Processing 2020 07\n",
      "   Downloaded yellow_tripdata_2020-07.parquet\n",
      "   Processed file written to yellow_tripdata_2020-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-07.parquet\n",
      "Processing 2020 08\n",
      "   Downloaded yellow_tripdata_2020-08.parquet\n",
      "   Processed file written to yellow_tripdata_2020-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-08.parquet\n",
      "Processing 2020 09\n",
      "   Downloaded yellow_tripdata_2020-09.parquet\n",
      "   Processed file written to yellow_tripdata_2020-09.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-09.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-09.parquet\n",
      "Processing 2020 10\n",
      "   Downloaded yellow_tripdata_2020-10.parquet\n",
      "   Processed file written to yellow_tripdata_2020-10.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-10.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-10.parquet\n",
      "Processing 2020 11\n",
      "   Downloaded yellow_tripdata_2020-11.parquet\n",
      "   Processed file written to yellow_tripdata_2020-11.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-11.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-11.parquet\n",
      "Processing 2020 12\n",
      "   Downloaded yellow_tripdata_2020-12.parquet\n",
      "   Processed file written to yellow_tripdata_2020-12.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2020-12.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2020-12.parquet\n",
      "Processing 2021 01\n",
      "   Downloaded yellow_tripdata_2021-01.parquet\n",
      "   Processed file written to yellow_tripdata_2021-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-01.parquet\n",
      "Processing 2021 02\n",
      "   Downloaded yellow_tripdata_2021-02.parquet\n",
      "   Processed file written to yellow_tripdata_2021-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-02.parquet\n",
      "Processing 2021 03\n",
      "   Downloaded yellow_tripdata_2021-03.parquet\n",
      "   Processed file written to yellow_tripdata_2021-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-03.parquet\n",
      "Processing 2021 04\n",
      "   Downloaded yellow_tripdata_2021-04.parquet\n",
      "   Processed file written to yellow_tripdata_2021-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-04.parquet\n",
      "Processing 2021 05\n",
      "   Downloaded yellow_tripdata_2021-05.parquet\n",
      "   Processed file written to yellow_tripdata_2021-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-05.parquet\n",
      "Processing 2021 06\n",
      "   Downloaded yellow_tripdata_2021-06.parquet\n",
      "   Processed file written to yellow_tripdata_2021-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-06.parquet\n",
      "Processing 2021 07\n",
      "   Downloaded yellow_tripdata_2021-07.parquet\n",
      "   Processed file written to yellow_tripdata_2021-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-07.parquet\n",
      "Processing 2021 08\n",
      "   Downloaded yellow_tripdata_2021-08.parquet\n",
      "   Processed file written to yellow_tripdata_2021-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-08.parquet\n",
      "Processing 2021 09\n",
      "   Downloaded yellow_tripdata_2021-09.parquet\n",
      "   Processed file written to yellow_tripdata_2021-09.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-09.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-09.parquet\n",
      "Processing 2021 10\n",
      "   Downloaded yellow_tripdata_2021-10.parquet\n",
      "   Processed file written to yellow_tripdata_2021-10.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-10.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-10.parquet\n",
      "Processing 2021 11\n",
      "   Downloaded yellow_tripdata_2021-11.parquet\n",
      "   Processed file written to yellow_tripdata_2021-11.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-11.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-11.parquet\n",
      "Processing 2021 12\n",
      "   Downloaded yellow_tripdata_2021-12.parquet\n",
      "   Processed file written to yellow_tripdata_2021-12.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2021-12.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2021-12.parquet\n",
      "Processing 2022 01\n",
      "   Downloaded yellow_tripdata_2022-01.parquet\n",
      "   Processed file written to yellow_tripdata_2022-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-01.parquet\n",
      "Processing 2022 02\n",
      "   Downloaded yellow_tripdata_2022-02.parquet\n",
      "   Processed file written to yellow_tripdata_2022-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-02.parquet\n",
      "Processing 2022 03\n",
      "   Downloaded yellow_tripdata_2022-03.parquet\n",
      "   Processed file written to yellow_tripdata_2022-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-03.parquet\n",
      "Processing 2022 04\n",
      "   Downloaded yellow_tripdata_2022-04.parquet\n",
      "   Processed file written to yellow_tripdata_2022-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-04.parquet\n",
      "Processing 2022 05\n",
      "   Downloaded yellow_tripdata_2022-05.parquet\n",
      "   Processed file written to yellow_tripdata_2022-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-05.parquet\n",
      "Processing 2022 06\n",
      "   Downloaded yellow_tripdata_2022-06.parquet\n",
      "   Processed file written to yellow_tripdata_2022-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-06.parquet\n",
      "Processing 2022 07\n",
      "   Downloaded yellow_tripdata_2022-07.parquet\n",
      "   Processed file written to yellow_tripdata_2022-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-07.parquet\n",
      "Processing 2022 08\n",
      "   Downloaded yellow_tripdata_2022-08.parquet\n",
      "   Processed file written to yellow_tripdata_2022-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-08.parquet\n",
      "Processing 2022 09\n",
      "   Downloaded yellow_tripdata_2022-09.parquet\n",
      "   Processed file written to yellow_tripdata_2022-09.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-09.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-09.parquet\n",
      "Processing 2022 10\n",
      "   Downloaded yellow_tripdata_2022-10.parquet\n",
      "   Processed file written to yellow_tripdata_2022-10.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-10.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-10.parquet\n",
      "Processing 2022 11\n",
      "   Downloaded yellow_tripdata_2022-11.parquet\n",
      "   Processed file written to yellow_tripdata_2022-11.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-11.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-11.parquet\n",
      "Processing 2022 12\n",
      "   Downloaded yellow_tripdata_2022-12.parquet\n",
      "   Processed file written to yellow_tripdata_2022-12.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2022-12.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2022-12.parquet\n",
      "Processing 2023 01\n",
      "   Downloaded yellow_tripdata_2023-01.parquet\n",
      "   Processed file written to yellow_tripdata_2023-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-01.parquet\n",
      "Processing 2023 02\n",
      "   Downloaded yellow_tripdata_2023-02.parquet\n",
      "   Processed file written to yellow_tripdata_2023-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-02.parquet\n",
      "Processing 2023 03\n",
      "   Downloaded yellow_tripdata_2023-03.parquet\n",
      "   Processed file written to yellow_tripdata_2023-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-03.parquet\n",
      "Processing 2023 04\n",
      "   Downloaded yellow_tripdata_2023-04.parquet\n",
      "   Processed file written to yellow_tripdata_2023-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-04.parquet\n",
      "Processing 2023 05\n",
      "   Downloaded yellow_tripdata_2023-05.parquet\n",
      "   Processed file written to yellow_tripdata_2023-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-05.parquet\n",
      "Processing 2023 06\n",
      "   Downloaded yellow_tripdata_2023-06.parquet\n",
      "   Processed file written to yellow_tripdata_2023-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-06.parquet\n",
      "Processing 2023 07\n",
      "   Downloaded yellow_tripdata_2023-07.parquet\n",
      "   Processed file written to yellow_tripdata_2023-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-07.parquet\n",
      "Processing 2023 08\n",
      "   Downloaded yellow_tripdata_2023-08.parquet\n",
      "   Processed file written to yellow_tripdata_2023-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-08.parquet\n",
      "Processing 2023 09\n",
      "   Downloaded yellow_tripdata_2023-09.parquet\n",
      "   Processed file written to yellow_tripdata_2023-09.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-09.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-09.parquet\n",
      "Processing 2023 10\n",
      "   Downloaded yellow_tripdata_2023-10.parquet\n",
      "   Processed file written to yellow_tripdata_2023-10.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-10.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-10.parquet\n",
      "Processing 2023 11\n",
      "   Downloaded yellow_tripdata_2023-11.parquet\n",
      "   Processed file written to yellow_tripdata_2023-11.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-11.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-11.parquet\n",
      "Processing 2023 12\n",
      "   Downloaded yellow_tripdata_2023-12.parquet\n",
      "   Processed file written to yellow_tripdata_2023-12.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2023-12.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2023-12.parquet\n",
      "Processing 2024 01\n",
      "   Downloaded yellow_tripdata_2024-01.parquet\n",
      "   Processed file written to yellow_tripdata_2024-01.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-01.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-01.parquet\n",
      "Processing 2024 02\n",
      "   Downloaded yellow_tripdata_2024-02.parquet\n",
      "   Processed file written to yellow_tripdata_2024-02.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-02.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-02.parquet\n",
      "Processing 2024 03\n",
      "   Downloaded yellow_tripdata_2024-03.parquet\n",
      "   Processed file written to yellow_tripdata_2024-03.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-03.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-03.parquet\n",
      "Processing 2024 04\n",
      "   Downloaded yellow_tripdata_2024-04.parquet\n",
      "   Processed file written to yellow_tripdata_2024-04.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-04.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-04.parquet\n",
      "Processing 2024 05\n",
      "   Downloaded yellow_tripdata_2024-05.parquet\n",
      "   Processed file written to yellow_tripdata_2024-05.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-05.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-05.parquet\n",
      "Processing 2024 06\n",
      "   Downloaded yellow_tripdata_2024-06.parquet\n",
      "   Processed file written to yellow_tripdata_2024-06.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-06.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-06.parquet\n",
      "Processing 2024 07\n",
      "   Downloaded yellow_tripdata_2024-07.parquet\n",
      "   Processed file written to yellow_tripdata_2024-07.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-07.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-07.parquet\n",
      "Processing 2024 08\n",
      "   Downloaded yellow_tripdata_2024-08.parquet\n",
      "   Processed file written to yellow_tripdata_2024-08.parquet\n",
      "   File uploaded to s3://csnow-bucket/yellow_tripdata/yellow_tripdata_2024-08.parquet\n",
      "   Inserted parquet into yellow_trip_data\n",
      "   Deleted yellow_tripdata_2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "# Download and process all files from 2019-01 to 2024-08\n",
    "for year in range(2019, 2025):\n",
    "    for month in range(1, 13):\n",
    "        if year == 2024 and month > 8:\n",
    "            break  # Only process until August 2024\n",
    "\n",
    "        print(f\"Processing {year}{month:02d}\")\n",
    "        print = indented_print\n",
    "             \n",
    "        # Format month to always have two digits\n",
    "        month_str = f\"{month:02d}\"\n",
    "        file_url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month_str}.parquet\"\n",
    "\n",
    "        file_name = f\"yellow_tripdata_{year}-{month_str}.parquet\"\n",
    "        s3_key = f\"yellow_tripdata/yellow_tripdata_{year}-{month_str}.parquet\"\n",
    "        \n",
    "        if file_exists_in_s3(s3_client, S3_BUCKET, s3_key):\n",
    "            print(f\"{s3_key} exists in S3, skipping ...\")\n",
    "            continue\n",
    "        else:\n",
    "            download_file(file_url)\n",
    "            pa_table = process_parquet(file_name)\n",
    "            upload_to_s3(s3_client, file_name, S3_BUCKET, s3_key)\n",
    "            \n",
    "            # Write the processed data to VASTDB (custom logic)\n",
    "            write_to_vastdb(session=session,\n",
    "                            bucket_name=VASTDB_TWITTER_INGEST_BUCKET, \n",
    "                            schema_name=VASTDB_TWITTER_INGEST_SCHEMA, \n",
    "                            table_name=VASTDB_TWITTER_INGEST_TABLE, \n",
    "                            pa_table=pa_table)\n",
    "    \n",
    "            # import_to_vastdb(\n",
    "            #     session=session,\n",
    "            #     bucket_name=VASTDB_TWITTER_INGEST_BUCKET, \n",
    "            #     schema_name=VASTDB_TWITTER_INGEST_SCHEMA, \n",
    "            #     table_name=VASTDB_TWITTER_INGEST_TABLE, \n",
    "            #     files_to_import=[f\"/{s3_key}\"]\n",
    "            # )\n",
    "            \n",
    "            # Delete the file after processing\n",
    "            delete_local_file(file_name)\n",
    "            print = original_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f039f2-fe90-4b90-9f65-0bd8489e621c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
